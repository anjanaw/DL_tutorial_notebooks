{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/Classwise_DICE_3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQ5MCVytMBzZ"
      },
      "source": [
        "# Class-wise Dice from 3D Patch\n",
        "Challenge-1: Patch to full volume conversion <br>\n",
        "Challenge-2: Saving full volume as same header as MRI/GT<br>\n",
        "Challenge-3: Calculating Class-wise Dice Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiSbpb1EwjnY"
      },
      "source": [
        "Downloading SVLS and Surface Dice codes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFNfvBfdKsT7",
        "outputId": "6290eb2a-4f21-4d57-87f9-aea3876e66f8"
      },
      "source": [
        "!rm -rf SVLS\n",
        "!git clone https://github.com/mobarakol/SVLS.git\n",
        "%cd SVLS\n",
        "!git clone https://github.com/deepmind/surface-distance.git\n",
        "!mv surface-distance surface_distance"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SVLS'...\n",
            "remote: Enumerating objects: 400, done.\u001b[K\n",
            "remote: Counting objects: 100% (400/400), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 400 (delta 351), reused 372 (delta 336), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (400/400), 120.63 KiB | 17.23 MiB/s, done.\n",
            "Resolving deltas: 100% (351/351), done.\n",
            "/content/SVLS\n",
            "Cloning into 'surface-distance'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 50 (delta 9), reused 9 (delta 8), pack-reused 35 (from 1)\u001b[K\n",
            "Receiving objects: 100% (50/50), 38.20 KiB | 19.10 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZNhk4-Od3FR"
      },
      "source": [
        "Install require packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdbUhZNUd6kl",
        "outputId": "875ae13f-db4b-4d16-a14b-9b3e0bd91a8b"
      },
      "source": [
        "!pip install -U -q SimpleITK"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FBq96oSpM7Da"
      },
      "source": [
        "### Download Dataset and Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1sI9SzGmKw1tLdRNhNROH7MKHdljKLSFi\n",
        "!gdown 1oZ9z-l9lBjKGNZCCTK819Z1ufwe90mg3\n",
        "\n",
        "!unzip -q ckpt_brats19.zip\n",
        "!unzip -q train_valid.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI5vbv85BzR_",
        "outputId": "b6d94bda-3fef-4e23-ffa0-97117f015e03"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1sI9SzGmKw1tLdRNhNROH7MKHdljKLSFi\n",
            "From (redirected): https://drive.google.com/uc?id=1sI9SzGmKw1tLdRNhNROH7MKHdljKLSFi&confirm=t&uuid=8ae5f78c-b890-4132-be0f-56c2b23aea2e\n",
            "To: /content/SVLS/ckpt_brats19.zip\n",
            "100% 64.0M/64.0M [00:02<00:00, 24.5MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1oZ9z-l9lBjKGNZCCTK819Z1ufwe90mg3\n",
            "From (redirected): https://drive.google.com/uc?id=1oZ9z-l9lBjKGNZCCTK819Z1ufwe90mg3&confirm=t&uuid=8fd84ee2-0892-4377-9aa1-5b57aac45f4d\n",
            "To: /content/SVLS/train_valid.zip\n",
            "100% 535M/535M [00:04<00:00, 124MB/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0PdKAYPWBx8"
      },
      "source": [
        "Demo"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the prediction: including padding(default volume 155 244 244)"
      ],
      "metadata": {
        "id": "W0Tt6RRorSlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from model import UNet3D\n",
        "import nibabel as nib\n",
        "import SimpleITK as sitk\n",
        "import random\n",
        "from glob import glob\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data._utils.collate import default_collate\n",
        "from datasets import custom_collate, determinist_collate, pad_batch_to_max_shape, \\\n",
        "pad_batch1_to_compatible_size, irm_min_max_preprocess, pad_or_crop_image\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "class EDiceLoss(nn.Module):\n",
        "    \"\"\"Dice loss tailored.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, do_sigmoid=True):\n",
        "        super(EDiceLoss, self).__init__()\n",
        "        self.do_sigmoid = do_sigmoid\n",
        "        self.device = \"cpu\"\n",
        "\n",
        "    def binary_dice(self, inputs, targets, metric_mode=False):\n",
        "        smooth = 1.\n",
        "        if metric_mode:\n",
        "            if targets.sum() == 0:\n",
        "                if inputs.sum() == 0:\n",
        "                    return torch.tensor(1., device=\"cuda\")\n",
        "                else:\n",
        "                    return torch.tensor(0., device=\"cuda\")\n",
        "        # Threshold the pred\n",
        "        intersection = EDiceLoss.compute_intersection(inputs, targets)\n",
        "        if metric_mode:\n",
        "            dice = (2 * intersection) / ((inputs.sum() + targets.sum()) * 1.0)\n",
        "        else:\n",
        "            dice = (2 * intersection + smooth) / (inputs.pow(2).sum() + targets.pow(2).sum() + smooth)\n",
        "        if metric_mode:\n",
        "            return dice\n",
        "        return 1 - dice\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_intersection(inputs, targets):\n",
        "        intersection = torch.sum(inputs * targets)\n",
        "        return intersection\n",
        "\n",
        "    def metric_classwise(self, inputs, target):\n",
        "        dices = []\n",
        "        for j in range(target.size(0)):\n",
        "            dice = []\n",
        "            dice.append(self.binary_dice(inputs[j]==1, target[j]==1, True))\n",
        "            dice.append(self.binary_dice(inputs[j]==2, target[j]==2, True))\n",
        "            dice.append(self.binary_dice(inputs[j]==3, target[j]==3, True))\n",
        "            dices.append(dice)\n",
        "\n",
        "        return dices\n",
        "\n",
        "def get_datasets_brats(data_root=None, normalisation=\"zscore\"):\n",
        "\n",
        "    data_root = pathlib.Path(data_root)\n",
        "    base_folder_train = pathlib.Path('data/BraTS19/train_train/').resolve()\n",
        "    base_folder_valid = pathlib.Path('data/BraTS19/train_valid/').resolve()\n",
        "    patients_dir_train = sorted([data_root/x.name for x in base_folder_train.iterdir() if (data_root/x.name).is_dir()])\n",
        "    patients_dir_valid = sorted([data_root/x.name for x in base_folder_valid.iterdir() if (data_root/x.name).is_dir()])\n",
        "    train_dataset = brats19(patients_dir_train, training=True, normalisation=normalisation)\n",
        "    val_dataset = brats19(patients_dir_valid, training=False, normalisation=normalisation)\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "\n",
        "class brats19(Dataset):\n",
        "    def __init__(self, patients_dir, training=True, no_seg=False, normalisation=\"minmax\"):\n",
        "        super(brats19, self).__init__()\n",
        "        self.normalisation = normalisation\n",
        "        self.training = training\n",
        "        self.datas = []\n",
        "        self.validation = no_seg\n",
        "        self.patterns = [ \"_flair\", \"_t1\", \"_t1ce\", \"_t2\"]\n",
        "        self.mean = dict(flair=0.0860377, t1=0.1216296, t1ce=0.07420689, t2=0.09033176)\n",
        "        if not no_seg:\n",
        "            self.patterns += [\"_seg\"]\n",
        "        for patient_dir in patients_dir:\n",
        "            patient_id = patient_dir.name\n",
        "            paths = [patient_dir / f\"{patient_id}{value}.nii.gz\" for value in self.patterns]\n",
        "            patient = dict(\n",
        "                id=patient_id, flair=paths[0], t1=paths[1], t1ce=paths[2],\n",
        "                t2=paths[3], seg=paths[4] if not no_seg else None\n",
        "            )\n",
        "            self.datas.append(patient)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        _patient = self.datas[idx]\n",
        "        patient_image = {key: self.load_nii(_patient[key]) for key in _patient if key not in [\"id\", \"seg\"]}\n",
        "        if _patient[\"seg\"] is not None:\n",
        "            patient_label = self.load_nii(_patient[\"seg\"])\n",
        "\n",
        "        patient_image = {key: (irm_min_max_preprocess(patient_image[key]) - self.mean[key]) for key in patient_image}\n",
        "        patient_image = np.stack([patient_image[key] for key in patient_image])\n",
        "        patient_label[patient_label==4] = 3\n",
        "        patient_label = patient_label[None,:,:,:]\n",
        "\n",
        "        # Remove maximum extent of the zero-background to make future crop more useful\n",
        "        z_indexes, y_indexes, x_indexes = np.nonzero(np.sum(patient_image, axis=0) != 0)\n",
        "\n",
        "        # Add 1 pixel in each side\n",
        "        zmin, ymin, xmin = [max(0, int(np.min(arr) - 1)) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        zmax, ymax, xmax = [int(np.max(arr) + 1) for arr in (z_indexes, y_indexes, x_indexes)]\n",
        "        patient_image, patient_label = patient_image.astype(\"float16\"), patient_label.astype(\"long\")\n",
        "        patient_image, patient_label = [torch.from_numpy(x) for x in [patient_image, patient_label]]\n",
        "        return dict(patient_id=_patient[\"id\"],\n",
        "                    image=patient_image, label=patient_label,\n",
        "                    seg_path=str(_patient[\"seg\"]),\n",
        "                    crop_indexes=((zmin, zmax), (ymin, ymax), (xmin, xmax)),\n",
        "                    )\n",
        "\n",
        "    @staticmethod\n",
        "    def load_nii(path_folder):\n",
        "        return sitk.GetArrayFromImage(sitk.ReadImage(str(path_folder)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.datas)\n",
        "\n",
        "\n",
        "def save_prediction_to_mri(args, predictions, patient_ids):\n",
        "    os.makedirs('predicted_segs', exist_ok=True)\n",
        "    for idx, patient_id in enumerate(patient_ids):\n",
        "        path = os.path.join(args.data_root, patient_id, patient_id+'_t1.nii.gz')\n",
        "        img_original = nib.load(path)\n",
        "        img_nifti = nib.Nifti1Image(predictions[idx], img_original.affine, header=img_original.header)\n",
        "        nib.save(img_nifti,'predicted_segs/'+patient_id+'_pred.nii.gz') #not as expected\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser(description='SVLS Brats Training')\n",
        "parser.add_argument('--batch_size', default=2, type=int,help='mini-batch size')\n",
        "parser.add_argument('--num_classes', default=4, type=int, help=\"num of classes\")\n",
        "parser.add_argument('--in_channels', default=4, type=int, help=\"num of input channels\")\n",
        "parser.add_argument('--train_option', default='SVLS', help=\"options:[SVLS, LS, OH]\")\n",
        "parser.add_argument('--epochs', default=200, type=int, help='number of total epochs to run')\n",
        "parser.add_argument('--data_root', default='train_valid', help='data directory')\n",
        "parser.add_argument('--ckpt_dir', default='ckpt_brats19', help='ckpt directory')\n",
        "args = parser.parse_args(args=[])\n",
        "\n",
        "\n",
        "_, val_dataset = get_datasets_brats(data_root=args.data_root)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "    pin_memory=False, num_workers=2)\n",
        "\n",
        "print('valid sample:',len(val_dataset), 'valid minibatch:',len(val_loader))\n",
        "model = UNet3D(inplanes=args.in_channels, num_classes=args.num_classes).cuda()\n",
        "model = torch.nn.DataParallel(model)\n",
        "criterion_dice = EDiceLoss().cuda()\n",
        "model.load_state_dict(torch.load(os.path.join(args.ckpt_dir, 'best_oh.pth.tar')))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    metrics = []\n",
        "    for i, batch in enumerate(val_loader):\n",
        "        targets = batch[\"label\"].squeeze(1).cuda(non_blocking=True)\n",
        "        inputs = batch[\"image\"].float().cuda()\n",
        "        preds = model(inputs)\n",
        "        preds = preds.data.max(1)[1].squeeze_(1)\n",
        "        if len(targets.shape) < 4:#if batch size=1\n",
        "            targets = targets.unsqueeze(0)\n",
        "        metric_ = criterion_dice.metric_classwise(preds, targets)\n",
        "        metrics.extend(metric_)\n",
        "        preds = preds.permute(0,3,2,1).detach().cpu().numpy()\n",
        "        save_prediction_to_mri(args, preds, batch['patient_id'])\n",
        "\n",
        "    metrics = list(zip(*metrics))\n",
        "    metrics = [torch.tensor(dice, device=\"cpu\").numpy() for dice in metrics]\n",
        "    avg_dices = np.mean(metrics,1)\n",
        "\n",
        "print('dice[Class-1:%.3f, Class-2:%.3f, Class-3:%.3f]'%(avg_dices[0], avg_dices[1], avg_dices[2]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3M_BFs5f_Da",
        "outputId": "1b109829-4bde-47b4-8ed0-8dea610b6b60"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid sample: 66 valid minibatch: 33\n",
            "dice[Class-1:0.589, Class-2:0.774, Class-3:0.776]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Obtaining Class-wise DICE metrics from saved 3D prediction and 3D GT mask"
      ],
      "metadata": {
        "id": "ZgatM7_gU5fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "class EDiceLoss(nn.Module):\n",
        "    \"\"\"Dice loss tailored.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, do_sigmoid=True):\n",
        "        super(EDiceLoss, self).__init__()\n",
        "        self.do_sigmoid = do_sigmoid\n",
        "        self.device = \"cpu\"\n",
        "\n",
        "    def binary_dice(self, inputs, targets, metric_mode=False):\n",
        "        smooth = 1.\n",
        "        if metric_mode:\n",
        "            if targets.sum() == 0:\n",
        "                if inputs.sum() == 0:\n",
        "                    return torch.tensor(1., device=\"cuda\")\n",
        "                else:\n",
        "                    return torch.tensor(0., device=\"cuda\")\n",
        "        # Threshold the pred\n",
        "        intersection = EDiceLoss.compute_intersection(inputs, targets)\n",
        "        if metric_mode:\n",
        "            dice = (2 * intersection) / ((inputs.sum() + targets.sum()) * 1.0)\n",
        "        else:\n",
        "            dice = (2 * intersection + smooth) / (inputs.pow(2).sum() + targets.pow(2).sum() + smooth)\n",
        "        if metric_mode:\n",
        "            return dice\n",
        "        return 1 - dice\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_intersection(inputs, targets):\n",
        "        intersection = torch.sum(inputs * targets)\n",
        "        return intersection\n",
        "\n",
        "    def metric_classwise(self, inputs, target):\n",
        "        dices = []\n",
        "        for j in range(target.size(0)):\n",
        "            dice = []\n",
        "            dice.append(self.binary_dice(inputs[j]==1, target[j]==1, True))\n",
        "            dice.append(self.binary_dice(inputs[j]==2, target[j]==2, True))\n",
        "            dice.append(self.binary_dice(inputs[j]==3, target[j]==3, True))\n",
        "            dices.append(dice)\n",
        "\n",
        "        return dices\n",
        "\n",
        "\n",
        "\n",
        "gt_dir_all = glob('/content/SVLS/train_valid/*/*_seg.nii.gz')\n",
        "metrics = []\n",
        "for path_gt in gt_dir_all:\n",
        "    patient_label = sitk.GetArrayFromImage(sitk.ReadImage(str(path_gt)))\n",
        "    patient_label[patient_label==4] = 3 # only need for BraTS19 dataset class 3 annoted as 4\n",
        "    pred_mask_dir = (os.path.dirname(path_gt)+'_pred.nii.gz').replace('train_valid', 'predicted_segs')\n",
        "    pred_mask = sitk.GetArrayFromImage(sitk.ReadImage(str(pred_mask_dir)))\n",
        "    metric_ = criterion_dice.metric_classwise(torch.tensor(pred_mask).unsqueeze(0), torch.tensor(patient_label).unsqueeze(0))\n",
        "    metrics.extend(metric_)\n",
        "\n",
        "\n",
        "metrics = list(zip(*metrics))\n",
        "metrics = [torch.tensor(dice, device=\"cpu\").numpy() for dice in metrics]\n",
        "avg_dices = np.mean(metrics,1)\n",
        "\n",
        "print('dice[Class-1:%.3f, Class-2:%.3f, Class-3:%.3f]'%(avg_dices[0], avg_dices[1], avg_dices[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eq3_5H7LDk1V",
        "outputId": "33a5f984-0101-47b6-b310-3b55604e2836"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dice[Class-1:0.589, Class-2:0.774, Class-3:0.776]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DPL7GDDbdYPy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}