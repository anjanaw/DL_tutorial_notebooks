{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1exTL4uUVpdB30kce71Gh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "027c0727a3854689b2c17d6eeaba760d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d45f67a58447629ec79c69d2d175ab",
              "IPY_MODEL_d778dcf1377d45c2b39415dddbd3162f",
              "IPY_MODEL_d8e9b5f06daf4bc2b00f0a12f112711d"
            ],
            "layout": "IPY_MODEL_e062ae1360ba4fa099052fe64636bd54"
          }
        },
        "11d45f67a58447629ec79c69d2d175ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81fa58d999a749ffbf5515ef93b20dcd",
            "placeholder": "​",
            "style": "IPY_MODEL_18feec1145fb43cb84cf637904bcd49c",
            "value": "Map: 100%"
          }
        },
        "d778dcf1377d45c2b39415dddbd3162f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bd7b64377ca42018c2289158b883957",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4b66ce35f5e415cbe0a13724dcf6a31",
            "value": 2
          }
        },
        "d8e9b5f06daf4bc2b00f0a12f112711d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf23c4dd9e4c4fd695031933ac554ef7",
            "placeholder": "​",
            "style": "IPY_MODEL_d39370ee24e642baaa5c181ef78941a6",
            "value": " 2/2 [00:00&lt;00:00, 48.73 examples/s]"
          }
        },
        "e062ae1360ba4fa099052fe64636bd54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81fa58d999a749ffbf5515ef93b20dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18feec1145fb43cb84cf637904bcd49c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bd7b64377ca42018c2289158b883957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4b66ce35f5e415cbe0a13724dcf6a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cf23c4dd9e4c4fd695031933ac554ef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d39370ee24e642baaa5c181ef78941a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a41627078fdd4fef8065888fe283d083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d94d78dd6094852a8a1a9efb39ad1e8",
              "IPY_MODEL_4dd27c472506441bb48af27d5a161070",
              "IPY_MODEL_190321ae1e804cd0bb423b40dbfe45d1"
            ],
            "layout": "IPY_MODEL_696466a644704c0aa1d9cb32721e4c97"
          }
        },
        "3d94d78dd6094852a8a1a9efb39ad1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63fe761a50ba41fa93088c7376fcc3fc",
            "placeholder": "​",
            "style": "IPY_MODEL_cba007181f684817b1cb0063abf21bff",
            "value": "Map: 100%"
          }
        },
        "4dd27c472506441bb48af27d5a161070": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45da1200d85042d5a51416d5b10e1ab0",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b367a929c5f4bdcab9529c3360f365e",
            "value": 2
          }
        },
        "190321ae1e804cd0bb423b40dbfe45d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b48918d7c1bb42439bc45100dd9465a4",
            "placeholder": "​",
            "style": "IPY_MODEL_6d1aa4352fc444b5af818988a943debc",
            "value": " 2/2 [00:00&lt;00:00, 64.90 examples/s]"
          }
        },
        "696466a644704c0aa1d9cb32721e4c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63fe761a50ba41fa93088c7376fcc3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cba007181f684817b1cb0063abf21bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45da1200d85042d5a51416d5b10e1ab0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b367a929c5f4bdcab9529c3360f365e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b48918d7c1bb42439bc45100dd9465a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d1aa4352fc444b5af818988a943debc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c2fe7f19f444e39bd80df2b70ef1b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d0e1154fcab4a08a0237b03925b4772",
              "IPY_MODEL_5ccd2ca06a39436cbcff7a128cbb7220",
              "IPY_MODEL_f63d72f94a9e4b40819ba36910f165a6"
            ],
            "layout": "IPY_MODEL_4ea1a8eaaf474386848022e923cb31df"
          }
        },
        "8d0e1154fcab4a08a0237b03925b4772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d1ee0df7bd74a00a7e164cef2ce16f9",
            "placeholder": "​",
            "style": "IPY_MODEL_137e7cf4ed0c4b38a50db5857f7d5fe6",
            "value": "Map: 100%"
          }
        },
        "5ccd2ca06a39436cbcff7a128cbb7220": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78372a3ccd5a4c549317b355d27001d5",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b0904abd322642039d4dac5c2fcacc2f",
            "value": 2
          }
        },
        "f63d72f94a9e4b40819ba36910f165a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_daea25b5e09c403ab484f14dd9d089a5",
            "placeholder": "​",
            "style": "IPY_MODEL_bd8847e66c6d459d8f50f0198ca47cc5",
            "value": " 2/2 [00:00&lt;00:00, 42.93 examples/s]"
          }
        },
        "4ea1a8eaaf474386848022e923cb31df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1ee0df7bd74a00a7e164cef2ce16f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137e7cf4ed0c4b38a50db5857f7d5fe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78372a3ccd5a4c549317b355d27001d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0904abd322642039d4dac5c2fcacc2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "daea25b5e09c403ab484f14dd9d089a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd8847e66c6d459d8f50f0198ca47cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea19108dfeba4ecebbba962e2e9652a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0117ba9ba7bf4ccb8c7172dbf708091f",
              "IPY_MODEL_983b7e3f654244a8a7d6e4c76b007ee3",
              "IPY_MODEL_e4c763440e1642b4ba85c23b485f6ec6"
            ],
            "layout": "IPY_MODEL_80d6afbb8719470b9714c905bfb0c40a"
          }
        },
        "0117ba9ba7bf4ccb8c7172dbf708091f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_442fbaab200843fdb94fe92f7f18a7ca",
            "placeholder": "​",
            "style": "IPY_MODEL_23cc2ff316d143c08687fa6b814bb9e5",
            "value": "Map: 100%"
          }
        },
        "983b7e3f654244a8a7d6e4c76b007ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9ef50d38619489a9b2814db85327064",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0947cf7ddd234818a7e3b18b5b1212dc",
            "value": 2
          }
        },
        "e4c763440e1642b4ba85c23b485f6ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_515bfb7879a9417782d813cff0211d4f",
            "placeholder": "​",
            "style": "IPY_MODEL_89ede1cb4783439992615f88e1f74e14",
            "value": " 2/2 [00:00&lt;00:00, 40.37 examples/s]"
          }
        },
        "80d6afbb8719470b9714c905bfb0c40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "442fbaab200843fdb94fe92f7f18a7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23cc2ff316d143c08687fa6b814bb9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9ef50d38619489a9b2814db85327064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0947cf7ddd234818a7e3b18b5b1212dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "515bfb7879a9417782d813cff0211d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89ede1cb4783439992615f88e1f74e14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/GPT2_QA_Finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtglDM63X5tN",
        "outputId": "6827a61d-a04a-47f0-b706-c97612a6947a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m471.0/480.6 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/134.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/194.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcYt80sfinYT",
        "outputId": "2462b8e5-4251-406d-bf43-db043098e750"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.47.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346,
          "referenced_widgets": [
            "027c0727a3854689b2c17d6eeaba760d",
            "11d45f67a58447629ec79c69d2d175ab",
            "d778dcf1377d45c2b39415dddbd3162f",
            "d8e9b5f06daf4bc2b00f0a12f112711d",
            "e062ae1360ba4fa099052fe64636bd54",
            "81fa58d999a749ffbf5515ef93b20dcd",
            "18feec1145fb43cb84cf637904bcd49c",
            "6bd7b64377ca42018c2289158b883957",
            "a4b66ce35f5e415cbe0a13724dcf6a31",
            "cf23c4dd9e4c4fd695031933ac554ef7",
            "d39370ee24e642baaa5c181ef78941a6"
          ]
        },
        "id": "GqDwtb-LXkbM",
        "outputId": "f4e6cbc9-beb6-447d-9e40-6cc78686c7ea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "027c0727a3854689b2c17d6eeaba760d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "<ipython-input-9-5238537375dd>:55: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 02:16, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.542056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.124552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.559626</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the capital of France?\n",
            "Answer: The capital of France is the capital of France.\n"
          ]
        }
      ],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Tie lm_head weights if missing\n",
        "if model.lm_head.weight.shape[0] != model.transformer.wte.weight.shape[0]:\n",
        "    model.tie_weights()\n",
        "\n",
        "# Add padding token to tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Example QA dataset\n",
        "qa_data = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Who wrote '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "]\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess_data(example):\n",
        "    input_text = f\"Question: {example['question']}\\nAnswer:\"\n",
        "    target_text = example[\"answer\"]\n",
        "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "    targets = tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    inputs[\"attention_mask\"] = inputs[\"attention_mask\"]\n",
        "    return inputs\n",
        "\n",
        "# Convert dataset to Huggingface Dataset object\n",
        "dataset = Dataset.from_list(qa_data)\n",
        "tokenized_dataset = dataset.map(preprocess_data, remove_columns=[\"question\", \"answer\"])\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./gpt2_qa_finetuned\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    report_to=[],  # Disable W&B or any reporting\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    eval_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Fine-tune the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./gpt2_qa_finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2_qa_finetuned\")\n",
        "\n",
        "# Test the model\n",
        "def generate_answer(question, model, tokenizer, device=\"cuda\"):\n",
        "    model.to(device)  # Move the model to the specified device\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    inputs = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)  # Move inputs to the same device\n",
        "    outputs = model.generate(inputs, max_length=100, num_beams=5, early_stopping=True, pad_token_id=tokenizer.eos_token_id)\n",
        "    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "# Determine device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question, model, tokenizer)\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(question, model, tokenizer, max_length=50, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Generate an answer using greedy search.\n",
        "    Args:\n",
        "        question (str): The input question.\n",
        "        model (GPT2LMHeadModel): The GPT-2 model.\n",
        "        tokenizer (GPT2Tokenizer): The tokenizer.\n",
        "        max_length (int): Maximum length of the generated text.\n",
        "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        str: The generated answer.\n",
        "    \"\"\"\n",
        "    # Move the model to the correct device\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Prepare input\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Start generating\n",
        "    generated_ids = input_ids\n",
        "    for _ in range(max_length):\n",
        "        # Get logits for the next token\n",
        "        outputs = model(input_ids=generated_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Select the token with the highest probability (greedy search)\n",
        "        next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "\n",
        "        # Append the predicted token to the sequence\n",
        "        generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
        "\n",
        "        # Stop if the model predicts the end-of-sequence token\n",
        "        if next_token_id.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Determine device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question, model, tokenizer)\n",
        "print(answer)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I21uFyNIXsKP",
        "outputId": "305fff75-ac25-438d-9763-db3fd8fef9c6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the capital of France?\n",
            "Answer: The capital of France is the capital of France.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Tie lm_head weights if missing\n",
        "if model.lm_head.weight.shape[0] != model.transformer.wte.weight.shape[0]:\n",
        "    model.tie_weights()\n",
        "\n",
        "# Add padding token to tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Example QA dataset\n",
        "qa_data = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Who wrote '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "]\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess_data(example):\n",
        "    input_text = f\"Question: {example['question']}\\nAnswer:\"\n",
        "    target_text = example[\"answer\"]\n",
        "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "    targets = tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "# Convert dataset to Huggingface Dataset object\n",
        "dataset = Dataset.from_list(qa_data)\n",
        "tokenized_dataset = dataset.map(preprocess_data, remove_columns=[\"question\", \"answer\"])\n",
        "\n",
        "# Define data loaders\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define optimizer and device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, optimizer, device, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        epoch_loss = 0\n",
        "        for batch in tqdm(train_loader):\n",
        "            input_ids = torch.stack(batch[\"input_ids\"]).to(device)\n",
        "            attention_mask = torch.stack(batch[\"attention_mask\"]).to(device)\n",
        "            labels = torch.stack(batch[\"labels\"]).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader)}\")\n",
        "\n",
        "# Validation loop (optional)\n",
        "def validate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader):\n",
        "            input_ids = torch.stack(batch[\"input_ids\"]).to(device)\n",
        "            attention_mask = torch.stack(batch[\"attention_mask\"]).to(device)\n",
        "            labels = torch.stack(batch[\"labels\"]).to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    print(f\"Validation Loss: {val_loss / len(val_loader)}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, optimizer, device)\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./gpt2_qa_finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2_qa_finetuned\")\n",
        "\n",
        "def generate_answer(question, model, tokenizer, max_length=50, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Generate an answer using greedy search.\n",
        "    Args:\n",
        "        question (str): The input question.\n",
        "        model (GPT2LMHeadModel): The GPT-2 model.\n",
        "        tokenizer (GPT2Tokenizer): The tokenizer.\n",
        "        max_length (int): Maximum length of the generated text.\n",
        "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        str: The generated answer.\n",
        "    \"\"\"\n",
        "    # Move the model to the correct device\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Prepare input\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Start generating\n",
        "    generated_ids = input_ids\n",
        "    for _ in range(max_length):\n",
        "        # Get logits for the next token\n",
        "        outputs = model(input_ids=generated_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Select the token with the highest probability (greedy search)\n",
        "        next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "\n",
        "        # Append the predicted token to the sequence\n",
        "        generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
        "\n",
        "        # Stop if the model predicts the end-of-sequence token\n",
        "        if next_token_id.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Determine device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question, model, tokenizer)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621,
          "referenced_widgets": [
            "a41627078fdd4fef8065888fe283d083",
            "3d94d78dd6094852a8a1a9efb39ad1e8",
            "4dd27c472506441bb48af27d5a161070",
            "190321ae1e804cd0bb423b40dbfe45d1",
            "696466a644704c0aa1d9cb32721e4c97",
            "63fe761a50ba41fa93088c7376fcc3fc",
            "cba007181f684817b1cb0063abf21bff",
            "45da1200d85042d5a51416d5b10e1ab0",
            "7b367a929c5f4bdcab9529c3360f365e",
            "b48918d7c1bb42439bc45100dd9465a4",
            "6d1aa4352fc444b5af818988a943debc"
          ]
        },
        "id": "heDvbZS0dGvb",
        "outputId": "8843259b-5e8b-4ffd-e702-968ce57b05f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a41627078fdd4fef8065888fe283d083"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  8.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 7.104681968688965\n",
            "Epoch 2/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 6.292819023132324\n",
            "Epoch 3/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 5.607349872589111\n",
            "Epoch 4/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 5.1459269523620605\n",
            "Epoch 5/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 11.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 4.897861003875732\n",
            "Epoch 6/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 5.431483268737793\n",
            "Epoch 7/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss: 4.674878120422363\n",
            "Epoch 8/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss: 4.1310224533081055\n",
            "Epoch 9/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss: 3.3114748001098633\n",
            "Epoch 10/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 3.6399283409118652\n",
            "Question: What is the capital of France?\n",
            "Answer: The capital of France is the capital of France\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Tie lm_head weights if missing\n",
        "if model.lm_head.weight.shape[0] != model.transformer.wte.weight.shape[0]:\n",
        "    model.tie_weights()\n",
        "\n",
        "# Add padding token to tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Example QA dataset\n",
        "qa_data = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Who wrote '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "]\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess_data(example):\n",
        "    input_text = f\"Question: {example['question']}\\nAnswer:\"\n",
        "    target_text = example[\"answer\"]\n",
        "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "    targets = tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "# Convert dataset to Huggingface Dataset object\n",
        "dataset = Dataset.from_list(qa_data)\n",
        "tokenized_dataset = dataset.map(preprocess_data, remove_columns=[\"question\", \"answer\"])\n",
        "\n",
        "# Define data loaders\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(tokenized_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Define optimizer, criterion, and device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "# Validation loop\n",
        "def validate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            input_ids = torch.stack(batch[\"input_ids\"]).to(device)\n",
        "            attention_mask = torch.stack(batch[\"attention_mask\"]).to(device)\n",
        "            labels = torch.stack(batch[\"labels\"]).to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Reshape logits and labels for CrossEntropyLoss\n",
        "            shift_logits = logits[..., :-1, :].contiguous()  # Shift logits\n",
        "            shift_labels = labels[..., 1:].contiguous()  # Shift labels\n",
        "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    return val_loss / len(val_loader)\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, train_loader, optimizer, criterion, device, num_epochs=3, save_dir=\"./best_model\"):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        epoch_loss = 0\n",
        "        for batch in tqdm(train_loader):\n",
        "            input_ids = torch.stack(batch[\"input_ids\"]).to(device)\n",
        "            attention_mask = torch.stack(batch[\"attention_mask\"]).to(device)\n",
        "            labels = torch.stack(batch[\"labels\"]).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Reshape logits and labels for CrossEntropyLoss\n",
        "            shift_logits = logits[..., :-1, :].contiguous()  # Shift logits\n",
        "            shift_labels = labels[..., 1:].contiguous()  # Shift labels\n",
        "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(train_loader)}\")\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1} Training Loss: {avg_train_loss}\")\n",
        "\n",
        "        # Validate after each epoch\n",
        "        val_loss = validate_model(model, val_loader, criterion, device)\n",
        "        print(f\"Epoch {epoch + 1} Validation Loss: {val_loss}\")\n",
        "\n",
        "        # Save the best model based on validation loss\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            model.save_pretrained(save_dir)\n",
        "            tokenizer.save_pretrained(save_dir)\n",
        "            print(f\"Saved best model with Validation Loss: {val_loss}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, optimizer, criterion, device)\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"./gpt2_qa_finetuned\")\n",
        "tokenizer.save_pretrained(\"./gpt2_qa_finetuned\")\n",
        "\n",
        "def generate_answer(question, model, tokenizer, max_length=50, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Generate an answer using greedy search.\n",
        "    Args:\n",
        "        question (str): The input question.\n",
        "        model (GPT2LMHeadModel): The GPT-2 model.\n",
        "        tokenizer (GPT2Tokenizer): The tokenizer.\n",
        "        max_length (int): Maximum length of the generated text.\n",
        "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        str: The generated answer.\n",
        "    \"\"\"\n",
        "    # Move the model to the correct device\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Prepare input\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Start generating\n",
        "    generated_ids = input_ids\n",
        "    for _ in range(max_length):\n",
        "        # Get logits for the next token\n",
        "        outputs = model(input_ids=generated_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Select the token with the highest probability (greedy search)\n",
        "        next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "\n",
        "        # Append the predicted token to the sequence\n",
        "        generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
        "\n",
        "        # Stop if the model predicts the end-of-sequence token\n",
        "        if next_token_id.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Determine device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question, model, tokenizer)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "8c2fe7f19f444e39bd80df2b70ef1b5c",
            "8d0e1154fcab4a08a0237b03925b4772",
            "5ccd2ca06a39436cbcff7a128cbb7220",
            "f63d72f94a9e4b40819ba36910f165a6",
            "4ea1a8eaaf474386848022e923cb31df",
            "4d1ee0df7bd74a00a7e164cef2ce16f9",
            "137e7cf4ed0c4b38a50db5857f7d5fe6",
            "78372a3ccd5a4c549317b355d27001d5",
            "b0904abd322642039d4dac5c2fcacc2f",
            "daea25b5e09c403ab484f14dd9d089a5",
            "bd8847e66c6d459d8f50f0198ca47cc5"
          ]
        },
        "id": "hCuLIaEpnzx1",
        "outputId": "a10db8f0-7421-42b0-ab2b-ad6483ecde75"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8c2fe7f19f444e39bd80df2b70ef1b5c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  7.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Training Loss: 11.8451509475708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 1/1 [00:00<00:00, 43.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Loss: nan\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00,  9.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Training Loss: 7.646153450012207\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 1/1 [00:00<00:00, 55.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Validation Loss: nan\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 10.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Training Loss: 8.785937309265137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 1/1 [00:00<00:00, 40.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Validation Loss: nan\n",
            "Question: What is the capital of France?\n",
            "Answer: The capital of France is the capital of France.\n",
            "The capital of France is the capital of France.\n",
            "The capital of France is the capital of France.\n",
            "The capital of France is the capital of France.\n",
            "The capital of France is the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Load GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Tie lm_head weights if missing\n",
        "if model.lm_head.weight.shape[0] != model.transformer.wte.weight.shape[0]:\n",
        "    model.tie_weights()\n",
        "\n",
        "# Add padding token to tokenizer\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Example QA dataset\n",
        "qa_data = [\n",
        "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is Paris.\"},\n",
        "    {\"question\": \"Who wrote '1984'?\", \"answer\": \"George Orwell wrote '1984'.\"},\n",
        "]\n",
        "\n",
        "# Preprocess dataset\n",
        "def preprocess_data(example):\n",
        "    input_text = f\"Question: {example['question']}\\nAnswer:\"\n",
        "    target_text = example[\"answer\"]\n",
        "    inputs = tokenizer(input_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "    targets = tokenizer(target_text, truncation=True, padding=\"max_length\", max_length=50)\n",
        "\n",
        "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
        "    return inputs\n",
        "\n",
        "# Convert dataset to Huggingface Dataset object\n",
        "dataset = Dataset.from_list(qa_data)\n",
        "tokenized_dataset = dataset.map(preprocess_data, remove_columns=[\"question\", \"answer\"])\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_dataset = tokenized_dataset.select(range(1))  # First half for training\n",
        "val_dataset = tokenized_dataset.select(range(1, 2))  # Second half for validation\n",
        "\n",
        "# Define data loaders\n",
        "batch_size = 2\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define optimizer, criterion, and device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "# Validation loop\n",
        "def validate_model(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            input_ids = torch.stack(batch[\"input_ids\"]).to(device)\n",
        "            attention_mask = torch.stack(batch[\"attention_mask\"]).to(device)\n",
        "            labels = torch.stack(batch[\"labels\"]).to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Reshape logits and labels for CrossEntropyLoss\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    return val_loss / len(val_loader)\n",
        "\n",
        "# Training loop with validation and checkpoint saving\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=3, save_dir=\"./best_model\"):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "            input_ids = torch.stack(batch[\"input_ids\"]).to(device)\n",
        "            attention_mask = torch.stack(batch[\"attention_mask\"]).to(device)\n",
        "            labels = torch.stack(batch[\"labels\"]).to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            # Reshape logits and labels for CrossEntropyLoss\n",
        "            shift_logits = logits[..., :-1, :].contiguous()\n",
        "            shift_labels = labels[..., 1:].contiguous()\n",
        "            loss = criterion(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = epoch_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch + 1} Training Loss: {avg_train_loss}\")\n",
        "\n",
        "        # Validate after each epoch\n",
        "        val_loss = validate_model(model, val_loader, criterion, device)\n",
        "        print(f\"Epoch {epoch + 1} Validation Loss: {val_loss}\")\n",
        "\n",
        "        # Save the best model based on validation loss\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            model.save_pretrained(save_dir)\n",
        "            tokenizer.save_pretrained(save_dir)\n",
        "            print(f\"Saved best model with Validation Loss: {val_loss}\")\n",
        "\n",
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, device)\n",
        "\n",
        "\n",
        "def generate_answer(question, model, tokenizer, max_length=50, device=\"cuda\"):\n",
        "    \"\"\"\n",
        "    Generate an answer using greedy search.\n",
        "    Args:\n",
        "        question (str): The input question.\n",
        "        model (GPT2LMHeadModel): The GPT-2 model.\n",
        "        tokenizer (GPT2Tokenizer): The tokenizer.\n",
        "        max_length (int): Maximum length of the generated text.\n",
        "        device (str): Device to run the model on ('cuda' or 'cpu').\n",
        "\n",
        "    Returns:\n",
        "        str: The generated answer.\n",
        "    \"\"\"\n",
        "    # Move the model to the correct device\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    # Prepare input\n",
        "    input_text = f\"Question: {question}\\nAnswer:\"\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Start generating\n",
        "    generated_ids = input_ids\n",
        "    for _ in range(max_length):\n",
        "        # Get logits for the next token\n",
        "        outputs = model(input_ids=generated_ids)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Select the token with the highest probability (greedy search)\n",
        "        next_token_id = torch.argmax(logits[:, -1, :], dim=-1).unsqueeze(0)\n",
        "\n",
        "        # Append the predicted token to the sequence\n",
        "        generated_ids = torch.cat([generated_ids, next_token_id], dim=-1)\n",
        "\n",
        "        # Stop if the model predicts the end-of-sequence token\n",
        "        if next_token_id.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # Decode the generated tokens to text\n",
        "    answer = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Determine device\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "question = \"What is the capital of France?\"\n",
        "answer = generate_answer(question, model, tokenizer)\n",
        "print(answer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "ea19108dfeba4ecebbba962e2e9652a7",
            "0117ba9ba7bf4ccb8c7172dbf708091f",
            "983b7e3f654244a8a7d6e4c76b007ee3",
            "e4c763440e1642b4ba85c23b485f6ec6",
            "80d6afbb8719470b9714c905bfb0c40a",
            "442fbaab200843fdb94fe92f7f18a7ca",
            "23cc2ff316d143c08687fa6b814bb9e5",
            "e9ef50d38619489a9b2814db85327064",
            "0947cf7ddd234818a7e3b18b5b1212dc",
            "515bfb7879a9417782d813cff0211d4f",
            "89ede1cb4783439992615f88e1f74e14"
          ]
        },
        "id": "8pL0vwgEjYh-",
        "outputId": "ae8c0f34-d2fb-4ee8-ee8b-ef65a43f3882"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea19108dfeba4ecebbba962e2e9652a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1/1 [00:00<00:00,  8.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Training Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 1/1 [00:00<00:00, 30.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Validation Loss: nan\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1/1 [00:00<00:00,  7.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Training Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 1/1 [00:00<00:00, 47.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Validation Loss: nan\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 1/1 [00:00<00:00,  7.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Training Loss: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 1/1 [00:00<00:00, 51.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Validation Loss: nan\n",
            "Question: What is the capital of France?\n",
            "Answer: The capital of France is the capital of France.\n",
            "The capital of France is the capital of France.\n",
            "The capital of France is the capital of France.\n",
            "The capital of France is the capital of France.\n",
            "The capital of France is the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3mgJwGJImtaD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}