{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOsRyFi4u+0aDX4GhbKmoh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/Galore_Truncated_Randomized_CUR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVD"
      ],
      "metadata": {
        "id": "WHRVW09z4Mz-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CP3H3NE0c4B",
        "outputId": "5a610939-378f-42c5-aef0-dd5996726ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 10.747417211532593\n",
            "Orthogonality check (should be close to identity):\n",
            "False\n",
            "orthogonal mat: torch.Size([3072, 128])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# Generate a random 3072x3072 tensor\n",
        "A = torch.randn(3072, 3072)\n",
        "\n",
        "st = time.time()\n",
        "# Perform Singular Value Decomposition (SVD)\n",
        "U, S, Vh = torch.linalg.svd(A, full_matrices=False)\n",
        "\n",
        "# Take the first 128 columns of U to form a 3072x128 orthogonal matrix\n",
        "U_128 = U[:, :128]\n",
        "en = time.time()\n",
        "\n",
        "print('time:', en-st)\n",
        "# Verify orthogonality (U_128.T @ U_128 should be close to identity)\n",
        "orthogonality_check = U_128.T @ U_128\n",
        "identity_matrix = torch.eye(128, device=U_128.device)\n",
        "\n",
        "print(\"Orthogonality check (should be close to identity):\")\n",
        "print(torch.allclose(orthogonality_check, identity_matrix, atol=1e-6))\n",
        "\n",
        "print('orthogonal mat:', U_128.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Truncated SVD"
      ],
      "metadata": {
        "id": "D1P4x3J04Loy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Generate a random 3072x3072 tensor\n",
        "A = torch.randn(3072, 3072)\n",
        "\n",
        "st = time.time()\n",
        "# Use PyTorch's svd_lowrank (efficient low-rank SVD)\n",
        "U, S, Vh = torch.svd_lowrank(A, q=128)  # Compute only the first 128 singular values/vectors\n",
        "\n",
        "# Truncated projection: Reduce A to 3072x128\n",
        "A_128 = U @ torch.diag(S)\n",
        "en = time.time()\n",
        "\n",
        "print('time:', en-st)\n",
        "print(\"Reduced matrix shape:\", A_128.shape)  # Expected: (3072, 128)\n",
        "\n",
        "# Verify orthogonality\n",
        "orthogonality_check = U.T @ U\n",
        "identity_matrix = torch.eye(128, device=U.device)\n",
        "print(\"Orthogonality check (should be close to identity):\", torch.allclose(orthogonality_check, identity_matrix, atol=1e-6))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pA8DMkbq1Nze",
        "outputId": "9dceeac3-f469-4c36-a4ed-0318e2e7a694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 0.26743578910827637\n",
            "Reduced matrix shape: torch.Size([3072, 128])\n",
            "Orthogonality check (should be close to identity): True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomized SVD"
      ],
      "metadata": {
        "id": "UygNdnlQ4JPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def randomized_svd(A, k=128, n_iter=5):\n",
        "    \"\"\"\n",
        "    Compute the randomized SVD of matrix A.\n",
        "\n",
        "    Args:\n",
        "        A (torch.Tensor): Input matrix (m x n).\n",
        "        k (int): Number of singular values/vectors to compute.\n",
        "        n_iter (int): Number of power iterations (improves accuracy for structured matrices).\n",
        "\n",
        "    Returns:\n",
        "        U (torch.Tensor): Left singular vectors (m x k).\n",
        "        S (torch.Tensor): Singular values (k).\n",
        "        Vh (torch.Tensor): Right singular vectors (k x n).\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "\n",
        "    # Step 1: Random Projection\n",
        "    Q = torch.randn(n, k, device=A.device)  # Random Gaussian matrix\n",
        "    Y = A @ Q  # Project A onto a lower-dimensional space\n",
        "\n",
        "    # Step 2: Power Iteration (improves approximation for structured data)\n",
        "    for _ in range(n_iter):\n",
        "        Y = A @ (A.T @ Y)\n",
        "\n",
        "    # Step 3: Orthonormalization (QR decomposition)\n",
        "    Q, _ = torch.linalg.qr(Y)  # Q is m x k\n",
        "\n",
        "    # Step 4: Compute SVD on the projected small matrix\n",
        "    B = Q.T @ A  # k x n matrix\n",
        "    U_hat, S, Vh = torch.linalg.svd(B, full_matrices=False)  # SVD of reduced matrix\n",
        "\n",
        "    # Step 5: Compute final U\n",
        "    U = Q @ U_hat  # Convert back to original space\n",
        "\n",
        "    return U, S, Vh\n",
        "\n",
        "# Generate a large random 3072x3072 matrix\n",
        "A = torch.randn(3072, 3072, device=\"cuda\")  # Using GPU if available\n",
        "\n",
        "# Compute randomized SVD with 128 components\n",
        "U, S, Vh = randomized_svd(A, k=128, n_iter=5)\n",
        "\n",
        "# Verify results\n",
        "print(\"final U shape:\", U.shape)   # (3072, 128)\n",
        "print(\"S shape:\", S.shape)   # (128,)\n",
        "print(\"Vh shape:\", Vh.shape) # (128, 3072)\n",
        "\n",
        "# Verify orthogonality (U.T @ U should be identity)\n",
        "orthogonality_check = U.T @ U\n",
        "identity_matrix = torch.eye(128, device=U.device)\n",
        "print(\"Orthogonality check (should be close to identity):\", torch.allclose(orthogonality_check, identity_matrix, atol=1e-6))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKjkR9cw2l8e",
        "outputId": "8fa23b15-01d1-438e-80c1-8cb6e1259a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final U shape: torch.Size([3072, 128])\n",
            "S shape: torch.Size([128])\n",
            "Vh shape: torch.Size([128, 3072])\n",
            "Orthogonality check (should be close to identity): False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CUR Decomposition"
      ],
      "metadata": {
        "id": "wxR6jl4y35fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def cur_decomposition(A, k=128):\n",
        "    \"\"\"\n",
        "    Compute the CUR decomposition of matrix A.\n",
        "\n",
        "    Args:\n",
        "        A (torch.Tensor): Input matrix (m x n).\n",
        "        k (int): Number of rows and columns to select.\n",
        "\n",
        "    Returns:\n",
        "        C (torch.Tensor): Selected columns (m x k).\n",
        "        U (torch.Tensor): Low-rank representation (k x k).\n",
        "        R (torch.Tensor): Selected rows (k x n).\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "\n",
        "    # Compute column selection probabilities (based on squared column norms)\n",
        "    col_norms = torch.norm(A, dim=0) ** 2\n",
        "    col_probs = col_norms / torch.sum(col_norms)\n",
        "\n",
        "    # Select k columns based on probabilities\n",
        "    col_indices = torch.multinomial(col_probs, k, replacement=False)\n",
        "    C = A[:, col_indices]\n",
        "\n",
        "    # Compute row selection probabilities (based on squared row norms)\n",
        "    row_norms = torch.norm(A, dim=1) ** 2\n",
        "    row_probs = row_norms / torch.sum(row_norms)\n",
        "\n",
        "    # Select k rows based on probabilities\n",
        "    row_indices = torch.multinomial(row_probs, k, replacement=False)\n",
        "    R = A[row_indices, :]\n",
        "\n",
        "    # Compute U (pseudo-inverse of intersection submatrix)\n",
        "    W = A[row_indices[:, None], col_indices]  # Intersection submatrix\n",
        "    U = torch.linalg.pinv(W)  # Compute pseudo-inverse\n",
        "\n",
        "    return C, U, R\n",
        "\n",
        "# Generate a random 3072x3072 matrix\n",
        "A = torch.randn(3072, 3072, device=\"cuda\")  # Using GPU if available\n",
        "\n",
        "# Perform CUR decomposition with 128 selected columns/rows\n",
        "C, U, R = cur_decomposition(A, k=128)\n",
        "\n",
        "# Verify shapes\n",
        "print(\"C final shape:\", C.shape)   # Expected: (3072, 128)\n",
        "print(\"U shape:\", U.shape)   # Expected: (128, 128)\n",
        "print(\"R shape:\", R.shape)   # Expected: (128, 3072)\n",
        "\n",
        "# Check reconstruction error\n",
        "A_approx = C @ U @ R\n",
        "reconstruction_error = torch.norm(A - A_approx) / torch.norm(A)\n",
        "print(\"Relative reconstruction error:\", reconstruction_error.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dov8HaN73SHF",
        "outputId": "ab4c627a-1c13-4257-adbe-f67097a2c649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C shape: torch.Size([3072, 128])\n",
            "U shape: torch.Size([128, 128])\n",
            "R shape: torch.Size([128, 3072])\n",
            "Relative reconstruction error: 9.713813781738281\n",
            "orthogonal mat: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kerbel SVD"
      ],
      "metadata": {
        "id": "GcwLvwiH_R4L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def rbf_kernel_torch(A, gamma=None):\n",
        "    \"\"\"\n",
        "    Compute the RBF Kernel using PyTorch.\n",
        "\n",
        "    Args:\n",
        "        A (torch.Tensor): Input matrix (m x n).\n",
        "        gamma (float): Kernel coefficient (default: 1 / feature_dim).\n",
        "\n",
        "    Returns:\n",
        "        K (torch.Tensor): Kernel matrix (m x m).\n",
        "    \"\"\"\n",
        "    m, n = A.shape\n",
        "    if gamma is None:\n",
        "        gamma = 1.0 / n  # Default gamma = 1/n_features\n",
        "\n",
        "    # Compute squared Euclidean distance using torch.cdist\n",
        "    squared_distances = torch.cdist(A, A, p=2) ** 2\n",
        "\n",
        "    # Compute RBF Kernel\n",
        "    K = torch.exp(-gamma * squared_distances)\n",
        "    return K\n",
        "\n",
        "def kernel_svd(A, k=128):\n",
        "    \"\"\"\n",
        "    Compute Kernel SVD (K-SVD) using the RBF kernel.\n",
        "\n",
        "    Args:\n",
        "        A (torch.Tensor): Input matrix (m x n).\n",
        "        k (int): Number of singular components to keep.\n",
        "\n",
        "    Returns:\n",
        "        U_k (torch.Tensor): Kernelized left singular vectors (m x k).\n",
        "        S_k (torch.Tensor): Singular values (k).\n",
        "        V_k (torch.Tensor): Kernelized right singular vectors (k x n).\n",
        "    \"\"\"\n",
        "    device = A.device\n",
        "\n",
        "    # Step 1: Compute Kernel Matrix using RBF\n",
        "    K = rbf_kernel_torch(A).to(device)  # Kernel transformation\n",
        "\n",
        "    # Step 2: Perform SVD on Kernel Matrix\n",
        "    U, S, Vh = torch.linalg.svd(K, full_matrices=False)\n",
        "\n",
        "    # Step 3: Select top-k components\n",
        "    U_k = U[:, :k]  # Left singular vectors\n",
        "    S_k = S[:k]  # Singular values\n",
        "    V_k = Vh[:k, :]  # Right singular vectors\n",
        "\n",
        "    return U_k, S_k, V_k\n",
        "\n",
        "# Generate a random 3072x3072 matrix (GPU-accelerated)\n",
        "A = torch.randn(3072, 3072, device=\"cuda\")  # Use GPU if available\n",
        "\n",
        "# Compute Kernel SVD with 128 components\n",
        "U_k, S_k, V_k = kernel_svd(A, k=128)\n",
        "\n",
        "# Verify output shapes\n",
        "print(\"U_k shape:\", U_k.shape)  # Expected: (3072, 128)\n",
        "print(\"S_k shape:\", S_k.shape)  # Expected: (128,)\n",
        "print(\"V_k shape:\", V_k.shape)  # Expected: (128, 3072)\n",
        "\n",
        "# Compute reconstruction error (optional)\n",
        "K_approx = U_k @ torch.diag(S_k) @ V_k\n",
        "error = torch.norm(K_approx - rbf_kernel_torch(A)) / torch.norm(rbf_kernel_torch(A))\n",
        "print(\"Relative reconstruction error:\", error.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1G4cmtK_SCR",
        "outputId": "c29085bc-817d-44e4-8eb2-b028a3221404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U_k shape: torch.Size([3072, 128])\n",
            "S_k shape: torch.Size([128])\n",
            "V_k shape: torch.Size([128, 3072])\n",
            "Relative reconstruction error: 0.11192391067743301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V1: FFT-Based Projection (Fast Fourier Transform)"
      ],
      "metadata": {
        "id": "RW7qdvKu9lgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def fft_svd_projection(A, k=128):\n",
        "    \"\"\"\n",
        "    Approximate SVD using Fast Fourier Transform (FFT),\n",
        "    projecting a 3072x3072 matrix to a lower-rank 3072x128 representation.\n",
        "\n",
        "    Args:\n",
        "        A (torch.Tensor): Input matrix (m x n).\n",
        "        k (int): Number of frequency components to keep (columns in the output).\n",
        "\n",
        "    Returns:\n",
        "        A_k (torch.Tensor): 3072x128 low-rank approximation using FFT.\n",
        "    \"\"\"\n",
        "    device = A.device\n",
        "    m, n = A.shape\n",
        "\n",
        "    # Compute 2D Fourier Transform\n",
        "    A_fft = torch.fft.fft2(A)\n",
        "\n",
        "    # Keep only the top-k frequencies along columns\n",
        "    A_fft_k = torch.zeros_like(A_fft)\n",
        "    A_fft_k[:, :k] = A_fft[:, :k]  # Retain low-frequency components in columns\n",
        "\n",
        "    # Inverse FFT to reconstruct low-rank matrix\n",
        "    A_k = torch.fft.ifft2(A_fft_k).real  # Take the real part after inverse FFT\n",
        "\n",
        "    return A_k[:, :k]  # Return only the first 128 columns\n",
        "\n",
        "# Fix the seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "# Generate a random 3072x3072 matrix\n",
        "A = torch.randn(3072, 3072, device=\"cuda\")  # Use GPU if available\n",
        "print(A.sum())\n",
        "\n",
        "# Compute FFT-based low-rank projection (output: 3072x128)\n",
        "A_k = fft_svd_projection(A, k=128)\n",
        "print(A_k.sum())\n",
        "\n",
        "# Verify output shape\n",
        "print(\"Low-rank projected matrix shape:\", A_k.shape)  # Expected: (3072, 128)\n",
        "\n",
        "# # Check approximation error\n",
        "# reconstruction_error = torch.norm(A[:, :128] - A_k) / torch.norm(A[:, :128])\n",
        "# print(\"Relative reconstruction error:\", reconstruction_error.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4oLhsnz374U",
        "outputId": "7b9b06bc-c53a-4577-8d0e-07e208ee3b3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-3362.1399, device='cuda:0')\n",
            "tensor(-186.6012, device='cuda:0')\n",
            "Low-rank projected matrix shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V2: FFT-Based Projection (Fast Fourier Transform)"
      ],
      "metadata": {
        "id": "1wwwXt__WH7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def fft_low_rank_projection_torch(matrix: torch.Tensor, rank_k: int = 128) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Perform FFT-based low-rank projection from [N x N] to [N x rank_k] using PyTorch.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): Input tensor of shape [N, N].\n",
        "        rank_k (int): Rank of the low-dimensional projection (number of frequency components to keep).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Projected tensor of shape [N, rank_k].\n",
        "    \"\"\"\n",
        "    assert matrix.shape[0] == matrix.shape[1], \"Input must be a square matrix\"\n",
        "    N = matrix.shape[0]\n",
        "    assert rank_k <= N, \"rank_k must be <= input dimension\"\n",
        "\n",
        "    # Step 1: FFT along the columns (dim=1)\n",
        "    matrix_fft = torch.fft.fft(matrix, dim=1)\n",
        "\n",
        "    # Step 2: Keep only the first rank_k frequency components\n",
        "    matrix_fft_reduced = matrix_fft[:, :rank_k]\n",
        "\n",
        "    # Step 3: Take real part (or use both real and imag if needed)\n",
        "    matrix_proj = matrix_fft_reduced.real\n",
        "\n",
        "    return matrix_proj\n",
        "\n",
        "# Example usage\n",
        "# Fix the seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "matrix = torch.randn(3072, 3072, device=\"cuda\")  # Use GPU if available\n",
        "print(matrix.sum())\n",
        "matrix_projected = fft_low_rank_projection_torch(matrix, rank_k=128)\n",
        "print(matrix_projected.sum())\n",
        "print(\"Projected shape:\", matrix_projected.shape)  # torch.Size([3072, 128])\n"
      ],
      "metadata": {
        "id": "zTRG5PPuWGyJ",
        "outputId": "cbb66e19-9fb5-484a-d998-cc20af9a2004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-3362.1399, device='cuda:0')\n",
            "tensor(-8680.4062, device='cuda:0')\n",
            "Projected shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V3: FFT-Based Projection (Fast Fourier Transform)"
      ],
      "metadata": {
        "id": "LRj5ygQnYCCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def fft_low_rank_projection_torch(matrix: torch.Tensor, rank_k: int = 128, use_complex: bool = True) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Perform FFT-based low-rank projection from [N x N] to [N x rank_k] (or [N x 2*rank_k] if use_complex) using PyTorch.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): Input tensor of shape [N, N].\n",
        "        rank_k (int): Rank of the low-dimensional projection (number of frequency components to keep).\n",
        "        use_complex (bool): If True, concatenate both real and imag parts (output shape: [N, 2*rank_k]).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Projected tensor of shape [N, rank_k] or [N, 2*rank_k].\n",
        "    \"\"\"\n",
        "    assert matrix.shape[0] == matrix.shape[1], \"Input must be a square matrix\"\n",
        "    N = matrix.shape[0]\n",
        "    assert rank_k <= N, \"rank_k must be <= input dimension\"\n",
        "\n",
        "    # FFT along columns\n",
        "    matrix_fft = torch.fft.fft(matrix, dim=1)\n",
        "\n",
        "    # Truncate to low-rank components\n",
        "    matrix_fft_reduced = matrix_fft[:, :rank_k]\n",
        "\n",
        "    if use_complex:\n",
        "        # Concatenate real and imag parts → shape: [N, 2 * rank_k]\n",
        "        matrix_proj = torch.cat([matrix_fft_reduced.real, matrix_fft_reduced.imag], dim=1)\n",
        "    else:\n",
        "        # Use only real part → shape: [N, rank_k]\n",
        "        matrix_proj = matrix_fft_reduced.real\n",
        "\n",
        "    return matrix_proj\n",
        "\n",
        "# Fix the seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "matrix = torch.randn(3072, 3072, device=\"cuda\")  # Use GPU if available\n",
        "print(matrix.sum())\n",
        "matrix_projected = fft_low_rank_projection_torch(matrix, rank_k=128)\n",
        "print(matrix_projected.sum())\n",
        "print(\"Projected shape:\", matrix_projected.shape)  # torch.Size([3072, 128])"
      ],
      "metadata": {
        "id": "PoDFcX1Y9BCd",
        "outputId": "efdcec09-a1ec-4fb0-cb82-2d89018fd871",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-3362.1399, device='cuda:0')\n",
            "tensor(-25897.6562, device='cuda:0')\n",
            "Projected shape: torch.Size([3072, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V4: FFT-Based Projection (Fast Fourier Transform)"
      ],
      "metadata": {
        "id": "cSwhYt_zac5Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft as fft\n",
        "\n",
        "def fft_low_rank_projection(matrix: torch.Tensor, k: int = 128) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Project a square matrix to rank-k approximation using FFT frequency component selection.\n",
        "\n",
        "    Args:\n",
        "        matrix: Input square tensor [N x N]\n",
        "        k: Target rank of the output tensor [N x k]\n",
        "\n",
        "    Returns:\n",
        "        Projected tensor of size [N x k] containing the most significant frequency components\n",
        "    \"\"\"\n",
        "    assert matrix.dim() == 2, \"Input must be a 2D tensor\"\n",
        "    assert matrix.size(0) == matrix.size(1), \"Input matrix must be square\"\n",
        "    assert k <= matrix.size(1), f\"Target rank k={k} must be ≤ original dimension {matrix.size(1)}\"\n",
        "\n",
        "    n = matrix.size(0)\n",
        "    device = matrix.device\n",
        "\n",
        "    # 1. Compute 2D FFT\n",
        "    fft_matrix = fft.fft2(matrix)\n",
        "\n",
        "    # 2. Create frequency mask for top-k components\n",
        "    center = n // 2\n",
        "    half_k = k // 2\n",
        "\n",
        "    # Calculate column ranges to keep (centered around DC component)\n",
        "    start_col = center - half_k\n",
        "    end_col = center + half_k + (k % 2)  # Handle odd k\n",
        "\n",
        "    # Create and apply mask\n",
        "    mask = torch.zeros_like(fft_matrix, dtype=torch.bool)\n",
        "    mask[:, start_col:end_col] = True\n",
        "    truncated_fft = fft_matrix * mask\n",
        "\n",
        "    # 3. Inverse FFT and column selection\n",
        "    low_rank_approx = fft.ifft2(truncated_fft).real\n",
        "    return low_rank_approx[:, start_col:end_col]\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create test matrix\n",
        "    torch.manual_seed(42)\n",
        "    A = torch.randn(3072, 3072, device=device)\n",
        "    print(A.sum())\n",
        "    # Project to rank-k approximation\n",
        "    k = 128\n",
        "    A_proj = fft_low_rank_projection(A, k=k)\n",
        "    print(A_proj.sum())\n",
        "    print(f\"Original: {A.shape} | Projected (k={k}): {A_proj.shape}\")\n",
        "    print(f\"Norm preservation: {A_proj.norm() / A.norm():.3f}\")"
      ],
      "metadata": {
        "id": "hr3UqOgBYPqf",
        "outputId": "c79f7489-1ff4-4bd0-d097-c8172b28991d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "tensor(-3362.1399, device='cuda:0')\n",
            "tensor(-0.7844, device='cuda:0')\n",
            "Original: torch.Size([3072, 3072]) | Projected (k=128): torch.Size([3072, 128])\n",
            "Norm preservation: 0.041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V5: Randomized FFT Low-Rank Projection"
      ],
      "metadata": {
        "id": "vmGaCV-zb9Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def randomized_fft_low_rank_projection(matrix: torch.Tensor, rank_k: int = 128) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Apply Randomized FFT-based projection to approximate low-rank version of a square matrix.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): Input [n x n] matrix.\n",
        "        rank_k (int): Target low-rank dimension.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Projected [n x 2*rank_k] matrix (real + imag parts).\n",
        "    \"\"\"\n",
        "    assert matrix.ndim == 2 and matrix.shape[0] == matrix.shape[1], \"matrix must be square\"\n",
        "\n",
        "    n = matrix.shape[0]\n",
        "    assert rank_k <= n, \"rank_k must be less than or equal to matrix dimension\"\n",
        "\n",
        "    # Step 1: FFT along columns\n",
        "    matrix_fft = torch.fft.fft(matrix, dim=1)  # shape: [n, n], dtype: complex\n",
        "\n",
        "    # Step 2: Random Gaussian projection, converted to complex type\n",
        "    Omega = torch.randn(n, rank_k, device=matrix.device).to(dtype=matrix_fft.dtype)\n",
        "    Y = matrix_fft @ Omega  # shape: [n, rank_k], dtype: complex\n",
        "\n",
        "    # Step 3: Concatenate real and imaginary parts\n",
        "    Y_proj = torch.cat([Y.real, Y.imag], dim=1)  # shape: [n, 2 * rank_k], dtype: float\n",
        "\n",
        "    return Y_proj\n",
        "\n",
        "# Example usage\n",
        "torch.manual_seed(42)\n",
        "matrix = torch.randn(3072, 3072, device=device)\n",
        "print(matrix.sum())\n",
        "matrix_projected = randomized_fft_low_rank_projection(matrix, rank_k=128)\n",
        "print(matrix_projected.sum())\n",
        "print(\"Projected shape:\", matrix_projected.shape)  # torch.Size([3072, 256])\n"
      ],
      "metadata": {
        "id": "rX0tdWSZapv0",
        "outputId": "1535696a-c5a5-4a8f-da61-bff822ce8578",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-3362.1399, device='cuda:0')\n",
            "tensor(886795.2500, device='cuda:0')\n",
            "Projected shape: torch.Size([3072, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V6: Randomized FFT Low-Rank Projection"
      ],
      "metadata": {
        "id": "K3EFLtPuc-94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft as fft\n",
        "from math import ceil\n",
        "\n",
        "def randomized_fft_low_rank(matrix: torch.Tensor, k: int = 128, oversampling: int = 10, power_iter: int = 0) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Randomized FFT for low-rank approximation using the subspace iteration method.\n",
        "\n",
        "    Args:\n",
        "        matrix: Input matrix [M x N]\n",
        "        k: Target rank\n",
        "        oversampling: Additional samples for numerical stability (typically 5-10)\n",
        "        power_iter: Number of power iterations to improve accuracy (0-2)\n",
        "\n",
        "    Returns:\n",
        "        Low-rank approximation matrix [M x k]\n",
        "    \"\"\"\n",
        "    m, n = matrix.shape\n",
        "    device = matrix.device\n",
        "    l = k + oversampling\n",
        "\n",
        "    # Step 1: Generate random test matrix\n",
        "    omega = torch.randn(n, l, device=device)\n",
        "\n",
        "    # Step 2: Form sketch matrix Y = A @ Ω\n",
        "    Y = matrix @ omega\n",
        "\n",
        "    # Step 3: Power iterations (optional)\n",
        "    for _ in range(power_iter):\n",
        "        Y = matrix @ (matrix.T @ Y)\n",
        "\n",
        "    # Step 4: Compute QR decomposition of Y to get basis Q\n",
        "    Q, _ = torch.linalg.qr(Y)\n",
        "\n",
        "    # Step 5: Project A onto the basis\n",
        "    B = Q.T @ matrix\n",
        "\n",
        "    # Step 6: Compute FFT of the small matrix B\n",
        "    B_fft = fft.fft(B, dim=1)\n",
        "\n",
        "    # Step 7: Keep only top-k frequency components\n",
        "    center = n // 2\n",
        "    half_k = k // 2\n",
        "    start_col = center - half_k\n",
        "    end_col = center + half_k + (k % 2)\n",
        "\n",
        "    mask = torch.zeros(n, dtype=torch.bool, device=device)\n",
        "    mask[start_col:end_col] = True\n",
        "    B_fft_trunc = B_fft[:, mask]\n",
        "\n",
        "    # Step 8: Inverse FFT and reconstruct\n",
        "    B_trunc = fft.ifft(B_fft_trunc, dim=1).real\n",
        "    return Q @ B_trunc\n",
        "\n",
        "# Example usage\n",
        "torch.manual_seed(42)\n",
        "matrix = torch.randn(3072, 3072, device=device)\n",
        "print(matrix.sum())\n",
        "matrix_projected = randomized_fft_low_rank(matrix, k=128)\n",
        "print(matrix_projected.sum())\n",
        "print(\"Projected shape:\", matrix_projected.shape)  # torch.Size([3072, 256])\n"
      ],
      "metadata": {
        "id": "wOiQlAhWcaKI",
        "outputId": "75e9ae71-5154-41ac-c53d-c7b871bc80b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-3362.1399, device='cuda:0')\n",
            "tensor(-109.6517, device='cuda:0')\n",
            "Projected shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V7: Frequency Domain Low-Rank Matrix Completion"
      ],
      "metadata": {
        "id": "2wFQYDahdwx4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def frequency_domain_low_rank_projection(matrix: torch.Tensor, rank_k: int = 128, mask_ratio: float = 0.5) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Frequency-Domain Low-Rank Projection with random frequency masking.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): Input [n x n] matrix.\n",
        "        rank_k (int): Desired output rank (e.g., 128).\n",
        "        mask_ratio (float): Fraction of frequency components to retain.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Projected matrix of shape [n x rank_k].\n",
        "    \"\"\"\n",
        "    n = matrix.shape[0]\n",
        "    assert matrix.shape[0] == matrix.shape[1], \"Only square matrices supported\"\n",
        "    assert 0 < mask_ratio <= 1.0, \"mask_ratio must be in (0, 1]\"\n",
        "\n",
        "    # Step 1: FFT\n",
        "    matrix_fft = torch.fft.fft2(matrix)\n",
        "\n",
        "    # Step 2: Apply random frequency mask\n",
        "    mask = (torch.rand_like(matrix_fft.real) < mask_ratio).to(matrix_fft.dtype)\n",
        "    matrix_fft_masked = matrix_fft * mask\n",
        "\n",
        "    # Step 3: Inverse FFT back to spatial domain\n",
        "    matrix_reconstructed = torch.fft.ifft2(matrix_fft_masked).real\n",
        "\n",
        "    # Step 4: Low-rank projection via SVD\n",
        "    U, S, Vh = torch.linalg.svd(matrix_reconstructed, full_matrices=False)\n",
        "\n",
        "    # Step 5: Project to rank_k (compressed form)\n",
        "    X_proj = U[:, :rank_k] * S[:rank_k]  # shape: [n, rank_k]\n",
        "\n",
        "    return X_proj\n",
        "\n",
        "# Example usage\n",
        "matrix = torch.randn(3072, 3072)\n",
        "matrix_projected = frequency_domain_low_rank_projection(matrix, rank_k=128, mask_ratio=0.4)\n",
        "print(\"Projected shape:\", matrix_projected.shape)  # torch.Size([3072, 128])\n"
      ],
      "metadata": {
        "id": "0ItNOhG_dLcR",
        "outputId": "d6201711-0f8e-4d2d-fc5e-bb3d1d4972b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projected shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V8: Frequency Domain Low-Rank Matrix Completion Projection"
      ],
      "metadata": {
        "id": "39NoMsVZe6ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def multiresolution_fft_low_rank_projection(matrix: torch.Tensor, rank_k: int = 128, coarse_scale: float = 0.25) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Perform multiresolution FFT-based low-rank projection.\n",
        "\n",
        "    Args:\n",
        "        matrix (torch.Tensor): Input square matrix [n x n].\n",
        "        rank_k (int): Target projection dimension.\n",
        "        coarse_scale (float): Scale factor for coarse FFT (e.g., 0.25 = 1/4 resolution).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Projected matrix of shape [n, rank_k].\n",
        "    \"\"\"\n",
        "    n = matrix.shape[0]\n",
        "    assert matrix.shape[0] == matrix.shape[1], \"Only square matrices are supported\"\n",
        "    assert 0 < coarse_scale < 1.0, \"coarse_scale must be between 0 and 1\"\n",
        "\n",
        "    # Step 1: High-resolution FFT\n",
        "    fine_fft = torch.fft.fft2(matrix)  # shape: [n, n], complex\n",
        "\n",
        "    # Step 2: Downsample and compute coarse FFT\n",
        "    down_n = int(n * coarse_scale)\n",
        "    matrix_downsampled = F.interpolate(matrix.unsqueeze(0).unsqueeze(0), size=(down_n, down_n), mode='bilinear', align_corners=False).squeeze()\n",
        "    coarse_fft = torch.fft.fft2(matrix_downsampled, s=(n, n))  # upsample back to [n, n]\n",
        "\n",
        "    # Step 3: Combine coarse and fine FFTs (e.g., average or weighted sum)\n",
        "    combined_fft = (fine_fft + coarse_fft) / 2  # shape: [n, n], complex\n",
        "\n",
        "    # Step 4: Inverse FFT to get multiresolution spatial signal\n",
        "    multires_spatial = torch.fft.ifft2(combined_fft).real  # shape: [n, n], real\n",
        "\n",
        "    # Step 5: Low-rank projection (SVD to rank_k)\n",
        "    U, S, Vh = torch.linalg.svd(multires_spatial, full_matrices=False)\n",
        "    X_proj = U[:, :rank_k] * S[:rank_k]  # shape: [n, rank_k]\n",
        "\n",
        "    return X_proj\n",
        "\n",
        "# Example usage\n",
        "matrix = torch.randn(3072, 3072)\n",
        "matrix_projected = multiresolution_fft_low_rank_projection(matrix, rank_k=128, coarse_scale=0.25)\n",
        "print(\"Projected shape:\", matrix_projected.shape)  # torch.Size([3072, 128])\n"
      ],
      "metadata": {
        "id": "IaVhOnTVeOba",
        "outputId": "3c186722-159d-4167-fccf-ddd770155080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projected shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v9: Multiresolution FFT (Fast Fourier Transform) for Low-Rank Approximation Projection"
      ],
      "metadata": {
        "id": "lTfpgGEGfvAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.fft import fft, ifft\n",
        "\n",
        "def multires_fft_projection(X, output_dim=128, resolution_levels=3, seed=42):\n",
        "    \"\"\"\n",
        "    Perform a multiresolution FFT-based projection from [N x D] to [N x output_dim].\n",
        "\n",
        "    Args:\n",
        "        X: Input matrix of shape [N x D].\n",
        "        output_dim: Target dimension after projection.\n",
        "        resolution_levels: Number of multiresolution splits (controls frequency mixing).\n",
        "        seed: Random seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        Projected matrix of shape [N x output_dim].\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)\n",
        "    N, D = X.shape\n",
        "    assert output_dim <= D, \"Output dim must be <= input dim\"\n",
        "    assert D % output_dim == 0, \"Input dim must be divisible by output dim\"\n",
        "\n",
        "    # Step 1: Apply FFT across each row (convert to frequency domain)\n",
        "    X_fft = fft(X, axis=1)\n",
        "\n",
        "    # Step 2: Multiresolution frequency mixing\n",
        "    mixed_freq = np.zeros((N, output_dim), dtype=np.complex128)\n",
        "    step = D // output_dim\n",
        "\n",
        "    for i in range(output_dim):\n",
        "        # Aggregate frequency bands at multiple resolutions\n",
        "        indices = [i * step + (j % step) for j in range(resolution_levels)]\n",
        "        for idx in indices:\n",
        "            weight = np.random.randn() + 1j * np.random.randn()  # complex weight\n",
        "            mixed_freq[:, i] += weight * X_fft[:, idx]\n",
        "\n",
        "    # Step 3: Convert back to time domain and take real part\n",
        "    projected = np.real(ifft(mixed_freq, axis=1))\n",
        "\n",
        "    return projected\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    D = 3072\n",
        "    output_dim = 128\n",
        "    X = np.random.randn(D, D)  # Simulate input matrix [3072 x 3072]\n",
        "    X_proj = multires_fft_projection(X, output_dim=output_dim)\n",
        "\n",
        "    print(\"Projected shape:\", X_proj.shape)  # Should be (3072, 128)\n"
      ],
      "metadata": {
        "id": "6ZGOdgAke2Ch",
        "outputId": "1b81fd41-e0ed-4560-a8ee-797f8fa50ac3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projected shape: (3072, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V10: Thresholding for Sparsity and Low-Rank Approximation Projection"
      ],
      "metadata": {
        "id": "pqghZzfTg0wQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy.fft import fft, ifft\n",
        "\n",
        "def fft_threshold_projection(W, output_dim=128, threshold=1e-2, axis=1):\n",
        "    \"\"\"\n",
        "    FFT-based low-rank and sparse projection from [D, D] to [D, output_dim].\n",
        "\n",
        "    Args:\n",
        "        W: Input matrix of shape [D, D] (square matrix).\n",
        "        output_dim: Desired output dimension (e.g., 128).\n",
        "        threshold: Threshold for sparsity (small coefficients are set to 0).\n",
        "        axis: Axis along which to apply FFT (1 = columns, 0 = rows).\n",
        "\n",
        "    Returns:\n",
        "        Projected matrix of shape [D, output_dim].\n",
        "    \"\"\"\n",
        "    # 1. Apply FFT along the specified axis\n",
        "    W_fft = fft(W, axis=axis)\n",
        "\n",
        "    # 2. Keep only real part if imaginary part is negligible\n",
        "    if np.all(np.isclose(W_fft.imag, 0)):\n",
        "        W_fft = W_fft.real\n",
        "\n",
        "    # 3. Thresholding for sparsity\n",
        "    W_fft[np.abs(W_fft) < threshold] = 0\n",
        "\n",
        "    # 4. Truncate to output_dim along the FFT axis (low-rank approximation)\n",
        "    if axis == 1:\n",
        "        W_proj_fft = W_fft[:, :output_dim]\n",
        "    else:\n",
        "        W_proj_fft = W_fft[:output_dim, :]\n",
        "\n",
        "    # 5. Optionally apply inverse FFT to get back to time domain (commented if you want spectral domain)\n",
        "    # W_proj = ifft(W_proj_fft, axis=axis).real\n",
        "    # return W_proj\n",
        "\n",
        "    return W_proj_fft\n",
        "\n",
        "# Example usage\n",
        "D = 3072\n",
        "W = np.random.randn(D, D)\n",
        "W_proj = fft_threshold_projection(W, output_dim=128, threshold=1e-2)\n",
        "\n",
        "print(\"Projected shape:\", W_proj.shape)\n"
      ],
      "metadata": {
        "id": "xjMRMaePfruF",
        "outputId": "b105c154-9973-4a9e-ab13-bdeed9512f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Projected shape: (3072, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V11: Subspace-Tracking with FFT for Low-Rank Approximation"
      ],
      "metadata": {
        "id": "SIADSgj-hGzo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft\n",
        "\n",
        "def fft_low_rank_projection(X: torch.Tensor, target_dim: int, mode='row') -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Perform low-rank projection of a square matrix using FFT and random subspace projection.\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): Input tensor of shape [N, N] (e.g., [3072, 3072])\n",
        "        target_dim (int): Desired reduced dimension (e.g., 128)\n",
        "        mode (str): 'row' or 'col' – whether to project rows or columns\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Projected tensor of shape [N, target_dim]\n",
        "    \"\"\"\n",
        "    assert X.ndim == 2 and X.shape[0] == X.shape[1], \"X must be a square 2D tensor\"\n",
        "\n",
        "    N = X.shape[0]\n",
        "\n",
        "    # Step 1: FFT transform along the mode\n",
        "    if mode == 'row':\n",
        "        X_fft = torch.fft.fft(X, dim=1)  # FFT along rows\n",
        "    elif mode == 'col':\n",
        "        X_fft = torch.fft.fft(X, dim=0)  # FFT along columns\n",
        "    else:\n",
        "        raise ValueError(\"Mode must be 'row' or 'col'\")\n",
        "\n",
        "    # Step 2: Use only the real part for projection\n",
        "    X_fft_real = X_fft.real\n",
        "\n",
        "    # Step 3: Generate a random Gaussian projection matrix\n",
        "    projection_matrix = torch.randn(N, target_dim, device=X.device) / (target_dim ** 0.5)\n",
        "\n",
        "    # Step 4: Project the real FFT subspace\n",
        "    X_proj = X_fft_real @ projection_matrix  # Shape: [3072, 128]\n",
        "\n",
        "    return X_proj\n",
        "\n",
        "X = torch.randn(3072, 3072)  # Input tensor\n",
        "X_proj = fft_low_rank_projection(X, target_dim=128)\n",
        "print(X_proj.shape)  # Should print: torch.Size([3072, 128])\n",
        "\n"
      ],
      "metadata": {
        "id": "qp8JXZ2pg24l",
        "outputId": "f187900a-6248-4a2c-dc57-9a8db9e22bc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V12: Spectral Clustering via FFT for Low-Rank Approximation Projection"
      ],
      "metadata": {
        "id": "gRAdqYYLjAbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.fft import fft, ifft\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from scipy.linalg import svd\n",
        "\n",
        "def fft_spectral_clustering_projection(matrix, target_dim):\n",
        "    \"\"\"\n",
        "    Project a matrix to lower dimension using FFT and spectral clustering\n",
        "\n",
        "    Args:\n",
        "    matrix: Input matrix of shape (n, n)\n",
        "    target_dim: Target dimension for projection (output will be (n, target_dim))\n",
        "\n",
        "    Returns:\n",
        "    Projected matrix of shape (n, target_dim)\n",
        "    \"\"\"\n",
        "    n = matrix.shape[0]\n",
        "\n",
        "    # Step 1: Apply 2D FFT to the matrix\n",
        "    fft_matrix = fft(fft(matrix, axis=0), axis=1)\n",
        "\n",
        "    # Step 2: Keep only the low-frequency components (top left quadrant)\n",
        "    # This is a simple low-pass filter approach\n",
        "    cutoff = target_dim // 2\n",
        "    filtered_fft = np.zeros_like(fft_matrix)\n",
        "    filtered_fft[:cutoff, :cutoff] = fft_matrix[:cutoff, :cutoff]\n",
        "\n",
        "    # Step 3: Inverse FFT to get a smoothed version of the matrix\n",
        "    smoothed_matrix = np.real(ifft(ifft(filtered_fft, axis=0), axis=1))\n",
        "\n",
        "    # Step 4: Perform spectral clustering on the smoothed matrix\n",
        "    # We'll use the eigenvectors as our projection\n",
        "    spectral = SpectralClustering(n_clusters=target_dim,\n",
        "                                affinity='precomputed',\n",
        "                                random_state=42)\n",
        "\n",
        "    # Create affinity matrix (absolute value of smoothed matrix)\n",
        "    affinity_matrix = np.abs(smoothed_matrix)\n",
        "\n",
        "    # Get the eigenvectors (this is the computationally intensive part)\n",
        "    # We'll use SVD to approximate the eigenvectors\n",
        "    _, _, vh = svd(affinity_matrix, full_matrices=False)\n",
        "    projection_matrix = vh[:target_dim, :].T\n",
        "\n",
        "    return projection_matrix\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Generate a random 3072x3072 matrix (in practice, use your actual matrix)\n",
        "    np.random.seed(42)\n",
        "    original_matrix = np.random.randn(3072, 3072)\n",
        "\n",
        "    # Project to 3072x128\n",
        "    projected_matrix = fft_spectral_clustering_projection(original_matrix, 128)\n",
        "\n",
        "    print(f\"Original matrix shape: {original_matrix.shape}\")\n",
        "    print(f\"Projected matrix shape: {projected_matrix.shape}\")"
      ],
      "metadata": {
        "id": "Vzv8LpVxiiwI",
        "outputId": "89e88148-c9d9-437a-c56e-cd9dfb5ea3f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original matrix shape: (3072, 3072)\n",
            "Projected matrix shape: (3072, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V14: Spectral Clustering via FFT for Low-Rank Approximation Projection"
      ],
      "metadata": {
        "id": "Hfd3es6WjFmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft\n",
        "import numpy as np\n",
        "from sklearn.cluster import SpectralClustering\n",
        "\n",
        "def fft_spectral_lowrank_projection(input_tensor, target_dim=128):\n",
        "    \"\"\"\n",
        "    Projects a [3072x3072] tensor to [3072x128] using FFT and spectral clustering.\n",
        "\n",
        "    Args:\n",
        "        input_tensor: torch.Tensor of shape [3072, 3072]\n",
        "        target_dim: desired output dimension (default: 128)\n",
        "\n",
        "    Returns:\n",
        "        projected_tensor: torch.Tensor of shape [3072, target_dim]\n",
        "    \"\"\"\n",
        "    assert input_tensor.shape == (3072, 3072), \"Input tensor must be 3072x3072\"\n",
        "\n",
        "    # Step 1: Compute 2D FFT of the input tensor\n",
        "    fft_tensor = torch.fft.fft2(input_tensor)\n",
        "\n",
        "    # Step 2: Shift zero frequency to center and get magnitude spectrum\n",
        "    fft_shifted = torch.fft.fftshift(fft_tensor)\n",
        "    magnitude_spectrum = torch.abs(fft_shifted)\n",
        "\n",
        "    # Step 3: Convert to numpy for spectral clustering (sklearn doesn't work with torch tensors)\n",
        "    magnitude_np = magnitude_spectrum.cpu().numpy()\n",
        "\n",
        "    # Step 4: Perform spectral clustering on the magnitude spectrum\n",
        "    # We'll cluster the rows into target_dim clusters\n",
        "    spectral = SpectralClustering(\n",
        "        n_clusters=target_dim,\n",
        "        affinity='nearest_neighbors',\n",
        "        n_neighbors=10,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    # Fit the model to the magnitude spectrum\n",
        "    cluster_labels = spectral.fit_predict(magnitude_np)\n",
        "\n",
        "    # Step 5: Create projection matrix by averaging within clusters\n",
        "    projection_matrix = torch.zeros((3072, target_dim), device=input_tensor.device)\n",
        "\n",
        "    for cluster_id in range(target_dim):\n",
        "        # Get indices of rows belonging to this cluster\n",
        "        cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
        "\n",
        "        if len(cluster_indices) > 0:\n",
        "            # Average the original rows (not the FFT) for this cluster\n",
        "            cluster_rows = input_tensor[cluster_indices]\n",
        "            projection_matrix[:, cluster_id] = cluster_rows.mean(dim=0)\n",
        "\n",
        "    return projection_matrix\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a random 3072x3072 tensor\n",
        "    original_tensor = torch.randn(3072, 3072)\n",
        "\n",
        "    # Project to 3072x128\n",
        "    projected_tensor = fft_spectral_lowrank_projection(original_tensor)\n",
        "\n",
        "    print(f\"Original shape: {original_tensor.shape}\")\n",
        "    print(f\"Projected shape: {projected_tensor.shape}\")"
      ],
      "metadata": {
        "id": "khXdjvfojBrs",
        "outputId": "6efadef7-54ac-4098-8ca8-4a2aab7fd4e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_spectral.py:703: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([3072, 3072])\n",
            "Projected shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V15: Spectral Clustering via FFT for Low-Rank Approximation Projection"
      ],
      "metadata": {
        "id": "gRWMBxk2mC6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft\n",
        "from sklearn.cluster import SpectralClustering\n",
        "import numpy as np\n",
        "\n",
        "def fft_spectral_projection(input_tensor, target_dim=128, n_neighbors=5):\n",
        "    \"\"\"\n",
        "    Projects [3072x3072] → [3072x128] using FFT frequency analysis + spectral clustering.\n",
        "    More efficient implementation than original version.\n",
        "\n",
        "    Args:\n",
        "        input_tensor: torch.Tensor of shape [3072, 3072]\n",
        "        target_dim: desired output dimension (default: 128)\n",
        "        n_neighbors: number of neighbors for spectral clustering affinity\n",
        "\n",
        "    Returns:\n",
        "        projected_tensor: torch.Tensor of shape [3072, target_dim]\n",
        "    \"\"\"\n",
        "    device = input_tensor.device\n",
        "\n",
        "    # Stage 1: FFT Frequency Compression\n",
        "    fft_tensor = torch.fft.fft2(input_tensor)\n",
        "    fft_shifted = torch.fft.fftshift(fft_tensor)\n",
        "    magnitude = torch.abs(fft_shifted)\n",
        "\n",
        "    # Compress columns first by keeping top frequencies\n",
        "    compressed_cols = magnitude[:, 1536-64:1536+64]  # Keep center 128 columns\n",
        "\n",
        "    # Stage 2: Spectral Clustering on Reduced Data\n",
        "    # Convert to numpy for sklearn (more efficient on smaller array)\n",
        "    data_np = compressed_cols.cpu().numpy()\n",
        "\n",
        "    # Use sparse affinity matrix for faster clustering\n",
        "    spectral = SpectralClustering(\n",
        "        n_clusters=target_dim,\n",
        "        affinity='nearest_neighbors',\n",
        "        n_neighbors=n_neighbors,\n",
        "        random_state=42,\n",
        "        assign_labels='discretize'  # Faster than eigen decomposition\n",
        "    )\n",
        "    cluster_labels = spectral.fit_predict(data_np)\n",
        "\n",
        "    # Stage 3: Create Projection Matrix\n",
        "    projection = torch.zeros((3072, target_dim), device=device)\n",
        "\n",
        "    for cluster_id in range(target_dim):\n",
        "        mask = torch.from_numpy(cluster_labels == cluster_id).to(device)\n",
        "        if mask.any():\n",
        "            # Weighted average based on magnitude importance\n",
        "            weights = magnitude[:, 1536-64:1536+64].mean(dim=1)\n",
        "            cluster_data = input_tensor[mask]\n",
        "            weighted_avg = (cluster_data * weights[mask].view(-1, 1)).sum(dim=0) / weights[mask].sum()\n",
        "            projection[:, cluster_id] = weighted_avg\n",
        "\n",
        "    return projection\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Create test tensor (could be covariance matrix, similarity matrix, etc.)\n",
        "    original = torch.randn(3072, 3072)\n",
        "    original = original @ original.T  # Make PSD for better clustering\n",
        "\n",
        "    projected = fft_spectral_projection(original)\n",
        "\n",
        "    print(f\"Original shape: {original.shape}\")\n",
        "    print(f\"Projected shape: {projected.shape}\")\n",
        "    print(f\"Projection norm: {torch.norm(projected, dim=0).mean():.4f}\")"
      ],
      "metadata": {
        "id": "9XuKgwgbkSr0",
        "outputId": "e1c1f8c6-ce08-4874-961c-f48cfae8091b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shape: torch.Size([3072, 3072])\n",
            "Projected shape: torch.Size([3072, 128])\n",
            "Projection norm: 944.1972\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V16: Thresholding for Sparsity and Low-Rank Approximation Projection"
      ],
      "metadata": {
        "id": "TO9vCywYl0zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def low_rank_sparse_projection(X, proj_dim=128, sparsity_ratio=0.1, thresholding='topk'):\n",
        "    \"\"\"\n",
        "    Projects input tensor X [3072 x 3072] to [3072 x 128] using a low-rank projection with thresholding.\n",
        "\n",
        "    Args:\n",
        "        X (Tensor): Input tensor of shape [3072, 3072]\n",
        "        proj_dim (int): Target projection dimension (e.g., 128)\n",
        "        sparsity_ratio (float): Proportion of values to keep (e.g., 0.1 means keep top 10%)\n",
        "        thresholding (str): 'topk' or 'value'\n",
        "\n",
        "    Returns:\n",
        "        X_proj (Tensor): Projected tensor of shape [3072, 128]\n",
        "    \"\"\"\n",
        "    input_dim = X.size(1)  # should be 3072\n",
        "\n",
        "    # Step 1: Initialize projection matrix W ∈ ℝ^{3072×128}\n",
        "    W = torch.randn(input_dim, proj_dim, device=X.device)\n",
        "\n",
        "    # Step 2: Apply projection\n",
        "    X_proj = X @ W  # shape: [3072 x 128]\n",
        "\n",
        "    # Step 3: Apply sparsity via thresholding\n",
        "    if thresholding == 'topk':\n",
        "        k = int(sparsity_ratio * X_proj.numel())\n",
        "        if k < 1:\n",
        "            return torch.zeros_like(X_proj)\n",
        "        # Get the k largest absolute values\n",
        "        threshold = torch.topk(X_proj.abs().flatten(), k, sorted=False).values.min()\n",
        "        X_proj = torch.where(X_proj.abs() >= threshold, X_proj, torch.zeros_like(X_proj))\n",
        "\n",
        "    elif thresholding == 'value':\n",
        "        threshold = sparsity_ratio  # use directly as a value threshold\n",
        "        X_proj = torch.where(X_proj.abs() >= threshold, X_proj, torch.zeros_like(X_proj))\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid thresholding type. Use 'topk' or 'value'.\")\n",
        "\n",
        "    return X_proj\n",
        "\n",
        "X = torch.randn(3072, 3072)\n",
        "X_proj = low_rank_sparse_projection(X, proj_dim=128, sparsity_ratio=0.05, thresholding='topk')\n",
        "print(X_proj.shape)  # should be [3072, 128]\n",
        "\n"
      ],
      "metadata": {
        "id": "A7_WlYcMk8Im",
        "outputId": "96552bb3-36b4-4672-d485-8f80d2d51830",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "v17: Thresholding for Sparsity and Low-Rank Approximation Projection"
      ],
      "metadata": {
        "id": "0SXeb2F1l60V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def sparse_lowrank_projection(input_tensor, output_dim=128, sparsity_threshold=0.01):\n",
        "    \"\"\"\n",
        "    Projects a large square matrix to a lower dimensional space with sparsity constraints\n",
        "\n",
        "    Args:\n",
        "        input_tensor: torch.Tensor of shape [d, d] (e.g., [3072, 3072])\n",
        "        output_dim: target dimension for projection (e.g., 128)\n",
        "        sparsity_threshold: values below this will be set to zero\n",
        "\n",
        "    Returns:\n",
        "        Projected tensor of shape [d, output_dim] (e.g., [3072, 128])\n",
        "    \"\"\"\n",
        "    d = input_tensor.size(0)\n",
        "\n",
        "    # Step 1: Create a random projection matrix with sparse initialization\n",
        "    # Using Kaiming initialization with adjusted sparsity\n",
        "    projection_matrix = torch.zeros(d, output_dim)\n",
        "    torch.nn.init.kaiming_uniform_(projection_matrix, mode='fan_in', nonlinearity='linear')\n",
        "\n",
        "    # Apply thresholding to enforce sparsity\n",
        "    projection_matrix[torch.abs(projection_matrix) < sparsity_threshold] = 0\n",
        "\n",
        "    # Step 2: Normalize columns to maintain stability\n",
        "    projection_matrix = F.normalize(projection_matrix, p=2, dim=0)\n",
        "\n",
        "    # Step 3: Project the input tensor\n",
        "    projected_tensor = torch.matmul(input_tensor, projection_matrix)\n",
        "\n",
        "    return projected_tensor\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a random 3072x3072 tensor\n",
        "    large_tensor = torch.randn(3072, 3072)\n",
        "\n",
        "    # Project to 3072x128\n",
        "    projected = sparse_lowrank_projection(large_tensor, output_dim=128)\n",
        "\n",
        "    print(f\"Input shape: {large_tensor.shape}\")\n",
        "    print(f\"Output shape: {projected.shape}\")"
      ],
      "metadata": {
        "id": "cwhyuQsrlu5F",
        "outputId": "25de7eec-89e4-42ec-a410-44d8db9c494d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3072, 3072])\n",
            "Output shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V18: FFT-based CUR projection"
      ],
      "metadata": {
        "id": "MZFjxfxlmohl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft\n",
        "\n",
        "def fft_based_projection(X: torch.Tensor, out_dim: int = 128, method='magnitude') -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    FFT-based CUR-style projection of a matrix [N x N] -> [N x out_dim]\n",
        "\n",
        "    Args:\n",
        "        X (torch.Tensor): Input matrix of shape [N, N]\n",
        "        out_dim (int): Target number of columns to project to\n",
        "        method (str): 'magnitude' to use top freq by energy, 'random' for uniform freq sampling\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Projected matrix of shape [N, out_dim]\n",
        "    \"\"\"\n",
        "    assert X.shape[0] == X.shape[1], \"Input must be square\"\n",
        "    N = X.shape[0]\n",
        "    assert out_dim <= N, \"Output dimension must be <= input size\"\n",
        "\n",
        "    # Step 1: FFT along the column axis (dim=0)\n",
        "    X_fft = torch.fft.fft(X, dim=0)\n",
        "\n",
        "    # Step 2: Choose frequency indices based on energy\n",
        "    if method == 'magnitude':\n",
        "        energy = torch.sum(torch.abs(X_fft)**2, dim=1)  # Energy along each freq row\n",
        "        topk_indices = torch.topk(energy, out_dim, largest=True).indices\n",
        "    elif method == 'random':\n",
        "        topk_indices = torch.randperm(N)[:out_dim]\n",
        "    else:\n",
        "        raise ValueError(\"method must be 'magnitude' or 'random'\")\n",
        "\n",
        "    # Step 3: Select those rows (frequencies), then inverse FFT\n",
        "    X_fft_selected = X_fft[topk_indices]\n",
        "    X_projected = torch.fft.ifft(X_fft_selected, dim=0).real  # [out_dim, N]\n",
        "\n",
        "    # Step 4: Transpose to [N x out_dim]\n",
        "    return X_projected.T.contiguous()\n",
        "\n",
        "# Example\n",
        "X = torch.randn(3072, 3072)\n",
        "X_proj = fft_based_projection(X, out_dim=128)\n",
        "print(X_proj.shape)  # Should be [3072, 128]\n"
      ],
      "metadata": {
        "id": "6MNqGhX8l5wV",
        "outputId": "a311fb09-f95c-4822-e7d1-80e8cc29d016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "V19: FFT-based CUR projection"
      ],
      "metadata": {
        "id": "XXezZVlJm085"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.fft\n",
        "import numpy as np\n",
        "\n",
        "def fft_based_cur_projection(input_tensor, target_dim=128):\n",
        "    \"\"\"\n",
        "    FFT-based CUR-like projection without SVD\n",
        "    Projects [3072 x 3072] tensor to [3072 x target_dim]\n",
        "\n",
        "    Args:\n",
        "        input_tensor: torch.Tensor of shape [3072, 3072]\n",
        "        target_dim: desired output dimension (default: 128)\n",
        "\n",
        "    Returns:\n",
        "        Projected tensor of shape [3072, target_dim]\n",
        "    \"\"\"\n",
        "    n = input_tensor.size(0)\n",
        "\n",
        "    # Step 1: Compute 2D FFT of the input matrix\n",
        "    fft_matrix = torch.fft.fft2(input_tensor)\n",
        "\n",
        "    # Step 2: Select important frequency components (top target_dim in magnitude)\n",
        "    magnitudes = torch.abs(fft_matrix)\n",
        "\n",
        "    # Flatten and get indices of top magnitudes\n",
        "    flat_magnitudes = magnitudes.view(-1)\n",
        "    _, top_indices = torch.topk(flat_magnitudes, k=target_dim)\n",
        "\n",
        "    # Convert flat indices to 2D coordinates\n",
        "    rows = top_indices // n\n",
        "    cols = top_indices % n\n",
        "\n",
        "    # Step 3: Create sampling probability distribution based on magnitude\n",
        "    prob_dist = flat_magnitudes / flat_magnitudes.sum()\n",
        "\n",
        "    # Step 4: Sample columns based on the probability distribution\n",
        "    # (Here we're actually selecting frequency components rather than columns)\n",
        "    sampled_indices = torch.multinomial(prob_dist, target_dim, replacement=False)\n",
        "\n",
        "    # Step 5: Construct the projection matrix using selected frequency components\n",
        "    projection_matrix = torch.zeros(n, target_dim, dtype=torch.complex64)\n",
        "\n",
        "    for i, idx in enumerate(sampled_indices):\n",
        "        row = idx // n\n",
        "        col = idx % n\n",
        "        projection_matrix[:, i] = fft_matrix[:, col] * (magnitudes[row, col] / magnitudes[:, col].sum())\n",
        "\n",
        "    # Step 6: Convert back to spatial domain\n",
        "    projected_real = torch.fft.ifft(projection_matrix, dim=0).real\n",
        "\n",
        "    # Normalize the output\n",
        "    projected_real = projected_real / torch.norm(projected_real, dim=0, keepdim=True)\n",
        "\n",
        "    return projected_real\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a random 3072x3072 tensor\n",
        "    input_tensor = torch.randn(3072, 3072)\n",
        "\n",
        "    # Project to 3072x128\n",
        "    projected = fft_based_cur_projection(input_tensor, target_dim=128)\n",
        "\n",
        "    print(f\"Input shape: {input_tensor.shape}\")\n",
        "    print(f\"Projected shape: {projected.shape}\")"
      ],
      "metadata": {
        "id": "uksWpgxzmtwT",
        "outputId": "185c49a4-884f-4756-9d5b-f9ca60342a0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3072, 3072])\n",
            "Projected shape: torch.Size([3072, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Byy7xhuGmyEy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}