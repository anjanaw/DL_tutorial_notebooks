{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMNW8yv5C1/QOJBT1FgzanE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "23b0f95d327a407da10c598a1b6cda81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_83129afa1cef44079614d4be2d8ac705",
              "IPY_MODEL_b1f86baf9ff04109a33e5deb9ce6e5d2",
              "IPY_MODEL_ddd7cb39fba04512bf97e55c0f24ed48"
            ],
            "layout": "IPY_MODEL_728dd3896e9842dbbdf319c2f2d42ce1"
          }
        },
        "83129afa1cef44079614d4be2d8ac705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc19edba5e04e7389d34aff3d3b1dd6",
            "placeholder": "​",
            "style": "IPY_MODEL_531f8fd26b814c90896d7c43e2e5215b",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "b1f86baf9ff04109a33e5deb9ce6e5d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24d84049348c44a0b309baabe7adb03a",
            "max": 54528,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9865b8ee4bfb4bdb9fb1e13116649ad8",
            "value": 54528
          }
        },
        "ddd7cb39fba04512bf97e55c0f24ed48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ec7429431e24472a4d9098c32c1fe12",
            "placeholder": "​",
            "style": "IPY_MODEL_6c4cf21759804d508b8899de2aeeb97f",
            "value": " 54.5k/54.5k [00:00&lt;00:00, 3.40MB/s]"
          }
        },
        "728dd3896e9842dbbdf319c2f2d42ce1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbc19edba5e04e7389d34aff3d3b1dd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "531f8fd26b814c90896d7c43e2e5215b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24d84049348c44a0b309baabe7adb03a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9865b8ee4bfb4bdb9fb1e13116649ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ec7429431e24472a4d9098c32c1fe12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c4cf21759804d508b8899de2aeeb97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f835a55bb104fa990bc3f29e3799c8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_149f1c2eea424d788f871a2668e871c8",
              "IPY_MODEL_a57d33656ede4b22bc6449386cec69ba",
              "IPY_MODEL_fc7dd605a2284c6b920d8ace965b3bc3"
            ],
            "layout": "IPY_MODEL_b56e3e4fb9c3454f8101af99cef4e4a2"
          }
        },
        "149f1c2eea424d788f871a2668e871c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27eacb86971f4d4fb9c527b3fb779bb3",
            "placeholder": "​",
            "style": "IPY_MODEL_3d46ed97b74646eaabae53244bb15a91",
            "value": "tokenizer.json: 100%"
          }
        },
        "a57d33656ede4b22bc6449386cec69ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38cec6770b69415bb90197a207c6d7fc",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bacccd3d14394ab9a9a2088f4dc8e598",
            "value": 9085657
          }
        },
        "fc7dd605a2284c6b920d8ace965b3bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd3c0146f48042efb8bebe1c0ab673a7",
            "placeholder": "​",
            "style": "IPY_MODEL_2ebf1e4d97bf4913afc3538d8ba49467",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 17.6MB/s]"
          }
        },
        "b56e3e4fb9c3454f8101af99cef4e4a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27eacb86971f4d4fb9c527b3fb779bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d46ed97b74646eaabae53244bb15a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38cec6770b69415bb90197a207c6d7fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bacccd3d14394ab9a9a2088f4dc8e598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd3c0146f48042efb8bebe1c0ab673a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ebf1e4d97bf4913afc3538d8ba49467": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "109a646fa83f4ed69bfd0acd80d816fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95c4a06d229340c68ed66ea6247b7920",
              "IPY_MODEL_51d553f86f3d4732a7b8726f8c814900",
              "IPY_MODEL_b6700984d3c2487bafe968448cd37bfe"
            ],
            "layout": "IPY_MODEL_594cae310588483489283f83294709ea"
          }
        },
        "95c4a06d229340c68ed66ea6247b7920": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_499afc6c066f42e7b6e8fac40e257a5c",
            "placeholder": "​",
            "style": "IPY_MODEL_d4af7688f9c8460985574d237a1c1e98",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "51d553f86f3d4732a7b8726f8c814900": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7debf135b2d04451991162496953f204",
            "max": 296,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1246f27831fb4495b51fc0b13e19ff4a",
            "value": 296
          }
        },
        "b6700984d3c2487bafe968448cd37bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5f7a6c1c9ff40f2a1a10158427e6820",
            "placeholder": "​",
            "style": "IPY_MODEL_4996b43753f0436d97bbf77e01d45682",
            "value": " 296/296 [00:00&lt;00:00, 18.5kB/s]"
          }
        },
        "594cae310588483489283f83294709ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "499afc6c066f42e7b6e8fac40e257a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4af7688f9c8460985574d237a1c1e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7debf135b2d04451991162496953f204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1246f27831fb4495b51fc0b13e19ff4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5f7a6c1c9ff40f2a1a10158427e6820": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4996b43753f0436d97bbf77e01d45682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1958e03ea53740e0975bd63fc15663d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fbbac5f3ee6449d1828ce18541b06c9c",
              "IPY_MODEL_a03615302f0f4e17b6287d45f3f2f38c",
              "IPY_MODEL_7b500b09382c482cab3ae10877f7eed3"
            ],
            "layout": "IPY_MODEL_159346697e5d498ca7517ae73afc9d35"
          }
        },
        "fbbac5f3ee6449d1828ce18541b06c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f316415b5c14dcd9372f4cbbb4b3c27",
            "placeholder": "​",
            "style": "IPY_MODEL_653a5e19c63246aeb383abd24d4c24ab",
            "value": "config.json: 100%"
          }
        },
        "a03615302f0f4e17b6287d45f3f2f38c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f49dbf77f044e22ba2ddfb867d91230",
            "max": 877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c1813fead7c4862801cc8a1f7e9c457",
            "value": 877
          }
        },
        "7b500b09382c482cab3ae10877f7eed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb6f4f81eb59410a8bdc3a0e872ae31a",
            "placeholder": "​",
            "style": "IPY_MODEL_918c1078e63343979b7b441ba9a9ae5e",
            "value": " 877/877 [00:00&lt;00:00, 67.2kB/s]"
          }
        },
        "159346697e5d498ca7517ae73afc9d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f316415b5c14dcd9372f4cbbb4b3c27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "653a5e19c63246aeb383abd24d4c24ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f49dbf77f044e22ba2ddfb867d91230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1813fead7c4862801cc8a1f7e9c457": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb6f4f81eb59410a8bdc3a0e872ae31a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "918c1078e63343979b7b441ba9a9ae5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ca694ef1d434387a0919cd454e33471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75e0d148bb8445dc8926cb5ed96f89ee",
              "IPY_MODEL_3919964976604d88bc8a562c098f331f",
              "IPY_MODEL_1296b5adb60b49ac97ad774fc1c156fd"
            ],
            "layout": "IPY_MODEL_7a91cf50d20f43a0a301040a2e1cf75b"
          }
        },
        "75e0d148bb8445dc8926cb5ed96f89ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7615eb62ded74ca7bc735effc90060eb",
            "placeholder": "​",
            "style": "IPY_MODEL_bb6e7af680614a3491639485649419d0",
            "value": "model.safetensors: 100%"
          }
        },
        "3919964976604d88bc8a562c098f331f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2dd1b74ad9a543e0ad1c6e774bf461fa",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6314ebf0f634df2bd3e7c8af20472af",
            "value": 2471645608
          }
        },
        "1296b5adb60b49ac97ad774fc1c156fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e2e5823fa4c45e6a965e06552bf004a",
            "placeholder": "​",
            "style": "IPY_MODEL_4a0730d97a404ba383e855d917eec9c6",
            "value": " 2.47G/2.47G [00:20&lt;00:00, 169MB/s]"
          }
        },
        "7a91cf50d20f43a0a301040a2e1cf75b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7615eb62ded74ca7bc735effc90060eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb6e7af680614a3491639485649419d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2dd1b74ad9a543e0ad1c6e774bf461fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6314ebf0f634df2bd3e7c8af20472af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e2e5823fa4c45e6a965e06552bf004a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a0730d97a404ba383e855d917eec9c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10fbc3f2ed0b4b12ae07d123556b7b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3357b358755b4ae9ab67da80a8246992",
              "IPY_MODEL_c319f8f9f2114c6781bf3901f9ac5701",
              "IPY_MODEL_5fe08591aeff411f82491edd1933da88"
            ],
            "layout": "IPY_MODEL_3bda24d7670e4446b56eec3076ece125"
          }
        },
        "3357b358755b4ae9ab67da80a8246992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cbcf12655b54d79aa9dd549600ed00c",
            "placeholder": "​",
            "style": "IPY_MODEL_91d5458be5104fd682375c7cfb831236",
            "value": "generation_config.json: 100%"
          }
        },
        "c319f8f9f2114c6781bf3901f9ac5701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a5b918005474d07affd098660df3479",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_502d698b31af4239807a73b6890cb341",
            "value": 189
          }
        },
        "5fe08591aeff411f82491edd1933da88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0f029c2e4f341aaaefa985c689b97d6",
            "placeholder": "​",
            "style": "IPY_MODEL_88551fd717f84784b4f0ce4a6aaec458",
            "value": " 189/189 [00:00&lt;00:00, 20.4kB/s]"
          }
        },
        "3bda24d7670e4446b56eec3076ece125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cbcf12655b54d79aa9dd549600ed00c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91d5458be5104fd682375c7cfb831236": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a5b918005474d07affd098660df3479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "502d698b31af4239807a73b6890cb341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c0f029c2e4f341aaaefa985c689b97d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88551fd717f84784b4f0ce4a6aaec458": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mobarakol/tutorial_notebooks/blob/main/Truncated_Galore_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vRwt4hZcy3v",
        "outputId": "ebfb2d02-4530-4da5-cba0-023a1a9cd2de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GaLore'...\n",
            "remote: Enumerating objects: 146, done.\u001b[K\n",
            "remote: Counting objects: 100% (90/90), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 146 (delta 57), reused 45 (delta 42), pack-reused 56 (from 2)\u001b[K\n",
            "Receiving objects: 100% (146/146), 442.55 KiB | 13.83 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "/content/GaLore\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jiaweizzhao/GaLore.git\n",
        "%cd GaLore"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install tensorly transformers peft bitsandbytes accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YcQ8QsOjxMN",
        "outputId": "66133656-f24a-459d-9155-df17a4978de6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/GaLore\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-afzk5ec6ir",
        "outputId": "dc60475a-4429-4adf-a2d6-a1321e34e161"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/GaLore\n",
            "CITATION.cff\t      galore_torch  peft_pretraining  run_glue.py  torchrun_main.py\n",
            "configs\t\t      imgs\t    README.md\t      scripts\n",
            "exp_requirements.txt  LICENSE\t    requirements.txt  setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c \"import bitsandbytes\""
      ],
      "metadata": {
        "id": "Q8V_pux7huRn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepare model"
      ],
      "metadata": {
        "id": "htSzWuOYmK5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 (better than standard FP4)\n",
        "#     bnb_4bit_use_double_quant=True,  # Uses secondary quantization for better precision\n",
        "#     bnb_4bit_compute_dtype=torch.float16  # Keeps computation in FP16 for stability\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    # quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "yMqHzkeHeYmo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "23b0f95d327a407da10c598a1b6cda81",
            "83129afa1cef44079614d4be2d8ac705",
            "b1f86baf9ff04109a33e5deb9ce6e5d2",
            "ddd7cb39fba04512bf97e55c0f24ed48",
            "728dd3896e9842dbbdf319c2f2d42ce1",
            "dbc19edba5e04e7389d34aff3d3b1dd6",
            "531f8fd26b814c90896d7c43e2e5215b",
            "24d84049348c44a0b309baabe7adb03a",
            "9865b8ee4bfb4bdb9fb1e13116649ad8",
            "7ec7429431e24472a4d9098c32c1fe12",
            "6c4cf21759804d508b8899de2aeeb97f",
            "2f835a55bb104fa990bc3f29e3799c8c",
            "149f1c2eea424d788f871a2668e871c8",
            "a57d33656ede4b22bc6449386cec69ba",
            "fc7dd605a2284c6b920d8ace965b3bc3",
            "b56e3e4fb9c3454f8101af99cef4e4a2",
            "27eacb86971f4d4fb9c527b3fb779bb3",
            "3d46ed97b74646eaabae53244bb15a91",
            "38cec6770b69415bb90197a207c6d7fc",
            "bacccd3d14394ab9a9a2088f4dc8e598",
            "bd3c0146f48042efb8bebe1c0ab673a7",
            "2ebf1e4d97bf4913afc3538d8ba49467",
            "109a646fa83f4ed69bfd0acd80d816fb",
            "95c4a06d229340c68ed66ea6247b7920",
            "51d553f86f3d4732a7b8726f8c814900",
            "b6700984d3c2487bafe968448cd37bfe",
            "594cae310588483489283f83294709ea",
            "499afc6c066f42e7b6e8fac40e257a5c",
            "d4af7688f9c8460985574d237a1c1e98",
            "7debf135b2d04451991162496953f204",
            "1246f27831fb4495b51fc0b13e19ff4a",
            "a5f7a6c1c9ff40f2a1a10158427e6820",
            "4996b43753f0436d97bbf77e01d45682",
            "1958e03ea53740e0975bd63fc15663d0",
            "fbbac5f3ee6449d1828ce18541b06c9c",
            "a03615302f0f4e17b6287d45f3f2f38c",
            "7b500b09382c482cab3ae10877f7eed3",
            "159346697e5d498ca7517ae73afc9d35",
            "5f316415b5c14dcd9372f4cbbb4b3c27",
            "653a5e19c63246aeb383abd24d4c24ab",
            "9f49dbf77f044e22ba2ddfb867d91230",
            "4c1813fead7c4862801cc8a1f7e9c457",
            "fb6f4f81eb59410a8bdc3a0e872ae31a",
            "918c1078e63343979b7b441ba9a9ae5e",
            "9ca694ef1d434387a0919cd454e33471",
            "75e0d148bb8445dc8926cb5ed96f89ee",
            "3919964976604d88bc8a562c098f331f",
            "1296b5adb60b49ac97ad774fc1c156fd",
            "7a91cf50d20f43a0a301040a2e1cf75b",
            "7615eb62ded74ca7bc735effc90060eb",
            "bb6e7af680614a3491639485649419d0",
            "2dd1b74ad9a543e0ad1c6e774bf461fa",
            "d6314ebf0f634df2bd3e7c8af20472af",
            "0e2e5823fa4c45e6a965e06552bf004a",
            "4a0730d97a404ba383e855d917eec9c6",
            "10fbc3f2ed0b4b12ae07d123556b7b7f",
            "3357b358755b4ae9ab67da80a8246992",
            "c319f8f9f2114c6781bf3901f9ac5701",
            "5fe08591aeff411f82491edd1933da88",
            "3bda24d7670e4446b56eec3076ece125",
            "4cbcf12655b54d79aa9dd549600ed00c",
            "91d5458be5104fd682375c7cfb831236",
            "6a5b918005474d07affd098660df3479",
            "502d698b31af4239807a73b6890cb341",
            "c0f029c2e4f341aaaefa985c689b97d6",
            "88551fd717f84784b4f0ce4a6aaec458"
          ]
        },
        "outputId": "c35b69ae-c686-4829-f2ca-fa185729ac35"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23b0f95d327a407da10c598a1b6cda81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f835a55bb104fa990bc3f29e3799c8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "109a646fa83f4ed69bfd0acd80d816fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1958e03ea53740e0975bd63fc15663d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ca694ef1d434387a0919cd454e33471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10fbc3f2ed0b4b12ae07d123556b7b7f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "apply galore"
      ],
      "metadata": {
        "id": "yI-aLyvbmNii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from galore_torch import GaLoreAdamW, GaLoreAdamW8bit, GaLoreAdafactor\n",
        "\n",
        "# make parameters with \"rank\" to a single group, if param_name has \"mlp\" or \"attn\"\n",
        "galore_params = []\n",
        "target_modules_list = [\"attn\", \"mlp\"]\n",
        "for module_name, module in model.named_modules():\n",
        "    if not isinstance(module, nn.Linear):\n",
        "        continue\n",
        "\n",
        "    if not any(target_key in module_name for target_key in target_modules_list):\n",
        "        continue\n",
        "\n",
        "    # print('enable GaLore for weights in module: ', module_name)\n",
        "    galore_params.append(module.weight)\n",
        "id_galore_params = [id(p) for p in galore_params]\n",
        "# make parameters without \"rank\" to another group\n",
        "regular_params = [p for p in model.parameters() if id(p) not in id_galore_params]\n",
        "# then call galore_adamw\n",
        "param_groups = [{'params': regular_params},\n",
        "                {'params': galore_params, 'rank': 128, 'update_proj_gap': 50, 'scale': 1, 'proj_type': \"std\"}]\n",
        "\n",
        "\n",
        "optimizer = GaLoreAdamW(param_groups, lr=1e-5, weight_decay=0.0)\n"
      ],
      "metadata": {
        "id": "gZo8Dzukfj1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bda01c7-418b-42db-b87b-27caecea2623"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/GaLore/galore_torch/adamw.py:49: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVD Galore From Scratch"
      ],
      "metadata": {
        "id": "5gdXdwtymbU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dependencies from transformers/optimization.py\n",
        "import math\n",
        "import warnings\n",
        "from typing import Callable, Iterable, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from transformers.utils.versions import require_version\n",
        "\n",
        "# from .galore_projector import GaLoreProjector\n",
        "# from .galore_projector_tensor import GaLoreProjectorTensor\n",
        "import torch\n",
        "\n",
        "class GaLoreProjector:\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0, proj_type='std'):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.proj_type = proj_type\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        if self.proj_type == 'std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type),full_rank_grad)\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad,self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "            low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='full')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix[0].t().to(full_rank_grad.device.type), full_rank_grad) @ self.ortho_matrix[1].t().to(full_rank_grad.device.type)\n",
        "\n",
        "        return low_rank_grad\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        if self.proj_type == 'std':\n",
        "            if low_rank_grad.shape[0] >= low_rank_grad.shape[1]:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if low_rank_grad.shape[0] <= low_rank_grad.shape[1]: # note this is different from std\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix[0].to(low_rank_grad.device.type), low_rank_grad) @ self.ortho_matrix[1].to(low_rank_grad.device.type)\n",
        "\n",
        "\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank, type):\n",
        "        module_params = weights\n",
        "\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            float_data = False\n",
        "            original_type = module_params.data.dtype\n",
        "            original_device = module_params.data.device\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            float_data = True\n",
        "            matrix = module_params.data\n",
        "\n",
        "        U, s, Vh = torch.linalg.svd(matrix, full_matrices = False)\n",
        "\n",
        "        #make the smaller matrix always to be orthogonal matrix\n",
        "        if type=='right':\n",
        "            B = Vh[:rank, :]\n",
        "            if not float_data:\n",
        "                B = B.to(original_device).type(original_type)\n",
        "            return B\n",
        "        elif type=='left':\n",
        "            A = U[:, :rank]\n",
        "            if not float_data:\n",
        "                A = A.to(original_device).type(original_type)\n",
        "            return A\n",
        "        elif type=='full':\n",
        "            A = U[:, :rank]\n",
        "            B = Vh[:rank, :]\n",
        "            if not float_data:\n",
        "                A = A.to(original_device).type(original_type)\n",
        "                B = B.to(original_device).type(original_type)\n",
        "            return [A, B]\n",
        "        else:\n",
        "            raise ValueError('type should be left, right or full')\n",
        "\n",
        "\n",
        "import torch\n",
        "from tensorly.decomposition import tucker\n",
        "from tensorly import tenalg\n",
        "\n",
        "# The GaLoreProjector class in Python implements a projection method using orthogonal matrix\n",
        "# decomposition for low-rank approximation of gradients for general tensors of dimension >2.\n",
        "# We use tensor decomposition using tensorly library: https://tensorly.org/stable/index.html\n",
        "class GaLoreProjectorTensor:\n",
        "    \"\"\"\n",
        "    A class that represents a projector for the GaLore algorithm.\n",
        "\n",
        "    Args:\n",
        "        rank (int): The rank of the projector.\n",
        "        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n",
        "        update_proj_gap (int, optional): The number of iterations between updating the orthogonal matrix. Defaults to 200.\n",
        "        scale (float, optional): The scaling factor for the projected gradients. Defaults to 1.0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.transformed_low_rank = None\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        \"\"\"\n",
        "        Projects the full-rank gradients onto the low-rank subspace.\n",
        "\n",
        "        Args:\n",
        "            full_rank_grad (torch.Tensor): The full-rank gradients.\n",
        "            iter (int): The current iteration.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed low-rank gradients.\n",
        "        \"\"\"\n",
        "        if self.ortho_matrix is None and iter % self.update_proj_gap == 0:\n",
        "            self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank)\n",
        "        self.transformed_low_rank = self.transform(self.ortho_matrix, full_rank_grad)\n",
        "        return self.transformed_low_rank\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        \"\"\"\n",
        "        Projects the low-rank gradients back to the full-rank space.\n",
        "\n",
        "        Args:\n",
        "            low_rank_grad (torch.Tensor): The low-rank gradients.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The full-rank gradients.\n",
        "        \"\"\"\n",
        "        full_rank_grad = self.inverse_transform(self.ortho_matrix, self.transformed_low_rank)\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank_all):\n",
        "        \"\"\"\n",
        "        Computes the orthogonal matrix using SVD decomposition.\n",
        "\n",
        "        Args:\n",
        "            weights (torch.Tensor): The weights to decompose.\n",
        "            rank_all (int): The desired rank of the decomposition.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the core and factors of the orthogonal matrix.\n",
        "        \"\"\"\n",
        "        module_params = weights\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            matrix = module_params.data\n",
        "        tucker_tensor = tucker(matrix, rank=rank_all)\n",
        "        return tucker_tensor\n",
        "\n",
        "    def transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors, transpose=True)\n",
        "\n",
        "    def inverse_transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Inverse transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The inverse transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors)\n",
        "\n",
        "\n",
        "\n",
        "class GaLoreAdamW(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements Adam algorithm with weight decay fix as introduced in [Decoupled Weight Decay\n",
        "    Regularization](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "    Parameters:\n",
        "        params (`Iterable[nn.parameter.Parameter]`):\n",
        "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
        "        lr (`float`, *optional*, defaults to 0.001):\n",
        "            The learning rate to use.\n",
        "        betas (`Tuple[float,float]`, *optional*, defaults to `(0.9, 0.999)`):\n",
        "            Adam's betas parameters (b1, b2).\n",
        "        eps (`float`, *optional*, defaults to 1e-06):\n",
        "            Adam's epsilon for numerical stability.\n",
        "        weight_decay (`float`, *optional*, defaults to 0.0):\n",
        "            Decoupled weight decay to apply.\n",
        "        correct_bias (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not to correct bias in Adam (for instance, in Bert TF repository they use `False`).\n",
        "        no_deprecation_warning (`bool`, *optional*, defaults to `False`):\n",
        "            A flag used to disable the deprecation warning (set to `True` to disable the warning).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params: Iterable[nn.parameter.Parameter],\n",
        "        lr: float = 1e-3,\n",
        "        betas: Tuple[float, float] = (0.9, 0.999),\n",
        "        eps: float = 1e-6,\n",
        "        weight_decay: float = 0.0,\n",
        "        correct_bias: bool = True,\n",
        "        no_deprecation_warning: bool = False,\n",
        "    ):\n",
        "        if not no_deprecation_warning:\n",
        "            warnings.warn(\n",
        "                \"This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch\"\n",
        "                \" implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this\"\n",
        "                \" warning\",\n",
        "                FutureWarning,\n",
        "            )\n",
        "        require_version(\"torch>=1.5.0\")  # add_ with alpha\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr} - should be >= 0.0\")\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[0]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[1]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps} - should be >= 0.0\")\n",
        "        defaults = {\"lr\": lr, \"betas\": betas, \"eps\": eps, \"weight_decay\": weight_decay, \"correct_bias\": correct_bias}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure: Callable = None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (`Callable`, *optional*): A closure that reevaluates the model and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if \"step\" not in state:\n",
        "                    state[\"step\"] = 0\n",
        "\n",
        "                if 'dim' not in group:\n",
        "                    group['dim'] = 2\n",
        "\n",
        "                # GaLore Projection\n",
        "                if \"rank\" in group:\n",
        "                    if \"projector\" not in state:\n",
        "                        if group['dim'] <=2:\n",
        "                            state[\"projector\"] = GaLoreProjector(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                        else:\n",
        "                            state[\"projector\"] = GaLoreProjectorTensor(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                    grad = state[\"projector\"].project(grad, state[\"step\"])\n",
        "\n",
        "                # State initialization\n",
        "                if \"exp_avg\" not in state:\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(grad)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(grad)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
        "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
        "\n",
        "                step_size = group[\"lr\"]\n",
        "                if group[\"correct_bias\"]:  # No bias correction for Bert\n",
        "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
        "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
        "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # compute norm gradient\n",
        "                norm_grad = exp_avg / denom\n",
        "\n",
        "                # GaLore Projection Back\n",
        "                if \"rank\" in group:\n",
        "                    norm_grad = state[\"projector\"].project_back(norm_grad)\n",
        "\n",
        "                p.add_(norm_grad, alpha=-step_size)\n",
        "\n",
        "                # Just adding the square of the weights to the loss function is *not*\n",
        "                # the correct way of using L2 regularization/weight decay with Adam,\n",
        "                # since that will interact with the m and v parameters in strange ways.\n",
        "                #\n",
        "                # Instead we want to decay the weights in a manner that doesn't interact\n",
        "                # with the m/v parameters. This is equivalent to adding the square\n",
        "                # of the weights to the loss with plain (non-momentum) SGD.\n",
        "                # Add weight decay at the end (fixed version)\n",
        "                if group[\"weight_decay\"] > 0.0:\n",
        "                    p.add_(p, alpha=(-group[\"lr\"] * group[\"weight_decay\"]))\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "OGsVmQHxlvqQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply SVD Galore"
      ],
      "metadata": {
        "id": "CgtekKRmnxTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 (better than standard FP4)\n",
        "    bnb_4bit_use_double_quant=True,  # Uses secondary quantization for better precision\n",
        "    bnb_4bit_compute_dtype=torch.float16  # Keeps computation in FP16 for stability\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "# from galore_torch import GaLoreAdamW, GaLoreAdamW8bit, GaLoreAdafactor\n",
        "\n",
        "# make parameters with \"rank\" to a single group, if param_name has \"mlp\" or \"attn\"\n",
        "galore_params = []\n",
        "target_modules_list = [\"attn\", \"mlp\"]\n",
        "for module_name, module in model.named_modules():\n",
        "    if not isinstance(module, nn.Linear):\n",
        "        continue\n",
        "\n",
        "    if not any(target_key in module_name for target_key in target_modules_list):\n",
        "        continue\n",
        "\n",
        "    # print('enable GaLore for weights in module: ', module_name)\n",
        "    galore_params.append(module.weight)\n",
        "id_galore_params = [id(p) for p in galore_params]\n",
        "# make parameters without \"rank\" to another group\n",
        "regular_params = [p for p in model.parameters() if id(p) not in id_galore_params]\n",
        "# then call galore_adamw\n",
        "param_groups = [{'params': regular_params},\n",
        "                {'params': galore_params, 'rank': 128, 'update_proj_gap': 50, 'scale': 1, 'proj_type': \"std\"}]\n",
        "\n",
        "\n",
        "optimizer = GaLoreAdamW(param_groups, lr=1e-5, weight_decay=0.0)"
      ],
      "metadata": {
        "id": "GVd5c8Dcm_fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Truncated-SVD Galore From Scratch"
      ],
      "metadata": {
        "id": "kAH3VajbnaN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dependencies from transformers/optimization.py\n",
        "import math\n",
        "import warnings\n",
        "from typing import Callable, Iterable, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from transformers.utils.versions import require_version\n",
        "\n",
        "# from .galore_projector import GaLoreProjector\n",
        "# from .galore_projector_tensor import GaLoreProjectorTensor\n",
        "import torch\n",
        "\n",
        "class GaLoreProjector:\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0, proj_type='std'):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.proj_type = proj_type\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        if self.proj_type == 'std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type),full_rank_grad)\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad,self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "            low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='full')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix[0].t().to(full_rank_grad.device.type), full_rank_grad) @ self.ortho_matrix[1].t().to(full_rank_grad.device.type)\n",
        "\n",
        "        return low_rank_grad\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        if self.proj_type == 'std':\n",
        "            if low_rank_grad.shape[0] >= low_rank_grad.shape[1]:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if low_rank_grad.shape[0] <= low_rank_grad.shape[1]: # note this is different from std\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix[0].to(low_rank_grad.device.type), low_rank_grad) @ self.ortho_matrix[1].to(low_rank_grad.device.type)\n",
        "\n",
        "\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank, type):\n",
        "        module_params = weights\n",
        "\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            float_data = False\n",
        "            original_type = module_params.data.dtype\n",
        "            original_device = module_params.data.device\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            float_data = True\n",
        "            matrix = module_params.data\n",
        "\n",
        "        # U, s, Vh = torch.linalg.svd(matrix, full_matrices = False)\n",
        "        U, S, Vh = torch.svd_lowrank(matrix, q=rank) # mobarak\n",
        "\n",
        "        #make the smaller matrix always to be orthogonal matrix\n",
        "        if type=='right':\n",
        "            B = Vh[:rank, :]\n",
        "            if not float_data:\n",
        "                B = B.to(original_device).type(original_type)\n",
        "            return B\n",
        "        elif type=='left':\n",
        "            A = U[:, :rank]\n",
        "            if not float_data:\n",
        "                A = A.to(original_device).type(original_type)\n",
        "            return A\n",
        "        elif type=='full':\n",
        "            A = U[:, :rank]\n",
        "            B = Vh[:rank, :]\n",
        "            if not float_data:\n",
        "                A = A.to(original_device).type(original_type)\n",
        "                B = B.to(original_device).type(original_type)\n",
        "            return [A, B]\n",
        "        else:\n",
        "            raise ValueError('type should be left, right or full')\n",
        "\n",
        "\n",
        "import torch\n",
        "from tensorly.decomposition import tucker\n",
        "from tensorly import tenalg\n",
        "\n",
        "# The GaLoreProjector class in Python implements a projection method using orthogonal matrix\n",
        "# decomposition for low-rank approximation of gradients for general tensors of dimension >2.\n",
        "# We use tensor decomposition using tensorly library: https://tensorly.org/stable/index.html\n",
        "class GaLoreProjectorTensor:\n",
        "    \"\"\"\n",
        "    A class that represents a projector for the GaLore algorithm.\n",
        "\n",
        "    Args:\n",
        "        rank (int): The rank of the projector.\n",
        "        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n",
        "        update_proj_gap (int, optional): The number of iterations between updating the orthogonal matrix. Defaults to 200.\n",
        "        scale (float, optional): The scaling factor for the projected gradients. Defaults to 1.0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.transformed_low_rank = None\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        \"\"\"\n",
        "        Projects the full-rank gradients onto the low-rank subspace.\n",
        "\n",
        "        Args:\n",
        "            full_rank_grad (torch.Tensor): The full-rank gradients.\n",
        "            iter (int): The current iteration.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed low-rank gradients.\n",
        "        \"\"\"\n",
        "        if self.ortho_matrix is None and iter % self.update_proj_gap == 0:\n",
        "            self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank)\n",
        "        self.transformed_low_rank = self.transform(self.ortho_matrix, full_rank_grad)\n",
        "        return self.transformed_low_rank\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        \"\"\"\n",
        "        Projects the low-rank gradients back to the full-rank space.\n",
        "\n",
        "        Args:\n",
        "            low_rank_grad (torch.Tensor): The low-rank gradients.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The full-rank gradients.\n",
        "        \"\"\"\n",
        "        full_rank_grad = self.inverse_transform(self.ortho_matrix, self.transformed_low_rank)\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank_all):\n",
        "        \"\"\"\n",
        "        Computes the orthogonal matrix using SVD decomposition.\n",
        "\n",
        "        Args:\n",
        "            weights (torch.Tensor): The weights to decompose.\n",
        "            rank_all (int): The desired rank of the decomposition.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the core and factors of the orthogonal matrix.\n",
        "        \"\"\"\n",
        "        module_params = weights\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            matrix = module_params.data\n",
        "        tucker_tensor = tucker(matrix, rank=rank_all)\n",
        "        return tucker_tensor\n",
        "\n",
        "    def transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors, transpose=True)\n",
        "\n",
        "    def inverse_transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Inverse transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The inverse transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors)\n",
        "\n",
        "\n",
        "\n",
        "class Truncated_GaLoreAdamW(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements Adam algorithm with weight decay fix as introduced in [Decoupled Weight Decay\n",
        "    Regularization](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "    Parameters:\n",
        "        params (`Iterable[nn.parameter.Parameter]`):\n",
        "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
        "        lr (`float`, *optional*, defaults to 0.001):\n",
        "            The learning rate to use.\n",
        "        betas (`Tuple[float,float]`, *optional*, defaults to `(0.9, 0.999)`):\n",
        "            Adam's betas parameters (b1, b2).\n",
        "        eps (`float`, *optional*, defaults to 1e-06):\n",
        "            Adam's epsilon for numerical stability.\n",
        "        weight_decay (`float`, *optional*, defaults to 0.0):\n",
        "            Decoupled weight decay to apply.\n",
        "        correct_bias (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not to correct bias in Adam (for instance, in Bert TF repository they use `False`).\n",
        "        no_deprecation_warning (`bool`, *optional*, defaults to `False`):\n",
        "            A flag used to disable the deprecation warning (set to `True` to disable the warning).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params: Iterable[nn.parameter.Parameter],\n",
        "        lr: float = 1e-3,\n",
        "        betas: Tuple[float, float] = (0.9, 0.999),\n",
        "        eps: float = 1e-6,\n",
        "        weight_decay: float = 0.0,\n",
        "        correct_bias: bool = True,\n",
        "        no_deprecation_warning: bool = False,\n",
        "    ):\n",
        "        if not no_deprecation_warning:\n",
        "            warnings.warn(\n",
        "                \"This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch\"\n",
        "                \" implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this\"\n",
        "                \" warning\",\n",
        "                FutureWarning,\n",
        "            )\n",
        "        require_version(\"torch>=1.5.0\")  # add_ with alpha\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr} - should be >= 0.0\")\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[0]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[1]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps} - should be >= 0.0\")\n",
        "        defaults = {\"lr\": lr, \"betas\": betas, \"eps\": eps, \"weight_decay\": weight_decay, \"correct_bias\": correct_bias}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure: Callable = None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (`Callable`, *optional*): A closure that reevaluates the model and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if \"step\" not in state:\n",
        "                    state[\"step\"] = 0\n",
        "\n",
        "                if 'dim' not in group:\n",
        "                    group['dim'] = 2\n",
        "\n",
        "                # GaLore Projection\n",
        "                if \"rank\" in group:\n",
        "                    if \"projector\" not in state:\n",
        "                        if group['dim'] <=2:\n",
        "                            state[\"projector\"] = GaLoreProjector(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                        else:\n",
        "                            state[\"projector\"] = GaLoreProjectorTensor(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                    grad = state[\"projector\"].project(grad, state[\"step\"])\n",
        "\n",
        "                # State initialization\n",
        "                if \"exp_avg\" not in state:\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(grad)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(grad)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
        "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
        "\n",
        "                step_size = group[\"lr\"]\n",
        "                if group[\"correct_bias\"]:  # No bias correction for Bert\n",
        "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
        "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
        "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # compute norm gradient\n",
        "                norm_grad = exp_avg / denom\n",
        "\n",
        "                # GaLore Projection Back\n",
        "                if \"rank\" in group:\n",
        "                    norm_grad = state[\"projector\"].project_back(norm_grad)\n",
        "\n",
        "                p.add_(norm_grad, alpha=-step_size)\n",
        "\n",
        "                # Just adding the square of the weights to the loss function is *not*\n",
        "                # the correct way of using L2 regularization/weight decay with Adam,\n",
        "                # since that will interact with the m and v parameters in strange ways.\n",
        "                #\n",
        "                # Instead we want to decay the weights in a manner that doesn't interact\n",
        "                # with the m/v parameters. This is equivalent to adding the square\n",
        "                # of the weights to the loss with plain (non-momentum) SGD.\n",
        "                # Add weight decay at the end (fixed version)\n",
        "                if group[\"weight_decay\"] > 0.0:\n",
        "                    p.add_(p, alpha=(-group[\"lr\"] * group[\"weight_decay\"]))\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "6ShXrpY4nHLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apply truncated-svd galore"
      ],
      "metadata": {
        "id": "-Pn6Xle-oERK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 (better than standard FP4)\n",
        "    bnb_4bit_use_double_quant=True,  # Uses secondary quantization for better precision\n",
        "    bnb_4bit_compute_dtype=torch.float16  # Keeps computation in FP16 for stability\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "# from galore_torch import GaLoreAdamW, GaLoreAdamW8bit, GaLoreAdafactor\n",
        "\n",
        "# make parameters with \"rank\" to a single group, if param_name has \"mlp\" or \"attn\"\n",
        "galore_params = []\n",
        "target_modules_list = [\"attn\", \"mlp\"]\n",
        "for module_name, module in model.named_modules():\n",
        "    if not isinstance(module, nn.Linear):\n",
        "        continue\n",
        "\n",
        "    if not any(target_key in module_name for target_key in target_modules_list):\n",
        "        continue\n",
        "\n",
        "    # print('enable GaLore for weights in module: ', module_name)\n",
        "    galore_params.append(module.weight)\n",
        "id_galore_params = [id(p) for p in galore_params]\n",
        "# make parameters without \"rank\" to another group\n",
        "regular_params = [p for p in model.parameters() if id(p) not in id_galore_params]\n",
        "# then call galore_adamw\n",
        "param_groups = [{'params': regular_params},\n",
        "                {'params': galore_params, 'rank': 128, 'update_proj_gap': 50, 'scale': 1, 'proj_type': \"std\"}]\n",
        "\n",
        "\n",
        "optimizer = Truncated_GaLoreAdamW(param_groups, lr=1e-5, weight_decay=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCCEkwPSoDc_",
        "outputId": "80f12fbb-204a-4322-cd1c-f1282651dee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e5870bd4efc5>:257: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fourier Galore From Scratch"
      ],
      "metadata": {
        "id": "YdaGai5v1DGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy dependencies from transformers/optimization.py\n",
        "import math\n",
        "import warnings\n",
        "from typing import Callable, Iterable, Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "\n",
        "from transformers.utils.versions import require_version\n",
        "\n",
        "# from .galore_projector import GaLoreProjector\n",
        "# from .galore_projector_tensor import GaLoreProjectorTensor\n",
        "\n",
        "def fft_svd_projection(A, k=128):\n",
        "    \"\"\"\n",
        "    Approximate SVD using Fast Fourier Transform (FFT),\n",
        "    projecting a 3072x3072 matrix to a lower-rank 3072x128 representation.\n",
        "\n",
        "    Args:\n",
        "        A (torch.Tensor): Input matrix (m x n).\n",
        "        k (int): Number of frequency components to keep (columns in the output).\n",
        "\n",
        "    Returns:\n",
        "        A_k (torch.Tensor): 3072x128 low-rank approximation using FFT.\n",
        "    \"\"\"\n",
        "    device = A.device\n",
        "    m, n = A.shape\n",
        "\n",
        "    # Compute 2D Fourier Transform\n",
        "    A_fft = torch.fft.fft2(A)\n",
        "\n",
        "    # Keep only the top-k frequencies along columns\n",
        "    A_fft_k = torch.zeros_like(A_fft)\n",
        "    A_fft_k[:, :k] = A_fft[:, :k]  # Retain low-frequency components in columns\n",
        "\n",
        "    # Inverse FFT to reconstruct low-rank matrix\n",
        "    A_k = torch.fft.ifft2(A_fft_k).real  # Take the real part after inverse FFT\n",
        "\n",
        "    return A_k[:, :k]  # Return only the first 128 columns\n",
        "\n",
        "\n",
        "class GaLoreProjector:\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0, proj_type='std'):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.proj_type = proj_type\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        if self.proj_type == 'std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if full_rank_grad.shape[0] >= full_rank_grad.shape[1]:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "                low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type),full_rank_grad)\n",
        "            else:\n",
        "                if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                    self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "                low_rank_grad = torch.matmul(full_rank_grad,self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='right')\n",
        "            low_rank_grad = torch.matmul(full_rank_grad, self.ortho_matrix.t().to(full_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='left')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix.t().to(full_rank_grad.device.type), full_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            if self.ortho_matrix is None or iter % self.update_proj_gap == 0:\n",
        "                self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank, type='full')\n",
        "            low_rank_grad = torch.matmul(self.ortho_matrix[0].t().to(full_rank_grad.device.type), full_rank_grad) @ self.ortho_matrix[1].t().to(full_rank_grad.device.type)\n",
        "\n",
        "        return low_rank_grad\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        if self.proj_type == 'std':\n",
        "            if low_rank_grad.shape[0] >= low_rank_grad.shape[1]:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'reverse_std':\n",
        "            if low_rank_grad.shape[0] <= low_rank_grad.shape[1]: # note this is different from std\n",
        "                full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "            else:\n",
        "                full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'right':\n",
        "            full_rank_grad = torch.matmul(low_rank_grad, self.ortho_matrix.to(low_rank_grad.device.type))\n",
        "        elif self.proj_type == 'left':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix.to(low_rank_grad.device.type), low_rank_grad)\n",
        "        elif self.proj_type == 'full':\n",
        "            full_rank_grad = torch.matmul(self.ortho_matrix[0].to(low_rank_grad.device.type), low_rank_grad) @ self.ortho_matrix[1].to(low_rank_grad.device.type)\n",
        "\n",
        "\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank, type):\n",
        "        module_params = weights\n",
        "\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            float_data = False\n",
        "            original_type = module_params.data.dtype\n",
        "            original_device = module_params.data.device\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            float_data = True\n",
        "            matrix = module_params.data\n",
        "\n",
        "        # U, s, Vh = torch.linalg.svd(matrix, full_matrices = False)\n",
        "        # U, S, Vh = torch.svd_lowrank(matrix, q=rank) # mobarak\n",
        "        U = fft_svd_projection(matrix, k=128)\n",
        "\n",
        "        # #make the smaller matrix always to be orthogonal matrix\n",
        "        # if type=='right':\n",
        "        #     B = Vh[:rank, :]\n",
        "        #     if not float_data:\n",
        "        #         B = B.to(original_device).type(original_type)\n",
        "        #     return B\n",
        "        # elif type=='left':\n",
        "        #     A = U[:, :rank]\n",
        "        #     if not float_data:\n",
        "        #         A = A.to(original_device).type(original_type)\n",
        "        #     return A\n",
        "        # elif type=='full':\n",
        "        #     A = U[:, :rank]\n",
        "        #     B = Vh[:rank, :]\n",
        "        #     if not float_data:\n",
        "        #         A = A.to(original_device).type(original_type)\n",
        "        #         B = B.to(original_device).type(original_type)\n",
        "        #     return [A, B]\n",
        "        # else:\n",
        "        #     raise ValueError('type should be left, right or full')\n",
        "\n",
        "\n",
        "import torch\n",
        "from tensorly.decomposition import tucker\n",
        "from tensorly import tenalg\n",
        "\n",
        "# The GaLoreProjector class in Python implements a projection method using orthogonal matrix\n",
        "# decomposition for low-rank approximation of gradients for general tensors of dimension >2.\n",
        "# We use tensor decomposition using tensorly library: https://tensorly.org/stable/index.html\n",
        "class GaLoreProjectorTensor:\n",
        "    \"\"\"\n",
        "    A class that represents a projector for the GaLore algorithm.\n",
        "\n",
        "    Args:\n",
        "        rank (int): The rank of the projector.\n",
        "        verbose (bool, optional): Whether to print verbose output. Defaults to False.\n",
        "        update_proj_gap (int, optional): The number of iterations between updating the orthogonal matrix. Defaults to 200.\n",
        "        scale (float, optional): The scaling factor for the projected gradients. Defaults to 1.0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, rank, verbose=False, update_proj_gap=200, scale=1.0):\n",
        "        self.rank = rank\n",
        "        self.verbose = verbose\n",
        "        self.update_proj_gap = update_proj_gap\n",
        "        self.scale = scale\n",
        "        self.ortho_matrix = None\n",
        "        self.transformed_low_rank = None\n",
        "\n",
        "    def project(self, full_rank_grad, iter):\n",
        "        \"\"\"\n",
        "        Projects the full-rank gradients onto the low-rank subspace.\n",
        "\n",
        "        Args:\n",
        "            full_rank_grad (torch.Tensor): The full-rank gradients.\n",
        "            iter (int): The current iteration.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed low-rank gradients.\n",
        "        \"\"\"\n",
        "        if self.ortho_matrix is None and iter % self.update_proj_gap == 0:\n",
        "            self.ortho_matrix = self.get_orthogonal_matrix(full_rank_grad, self.rank)\n",
        "        self.transformed_low_rank = self.transform(self.ortho_matrix, full_rank_grad)\n",
        "        return self.transformed_low_rank\n",
        "\n",
        "    def project_back(self, low_rank_grad):\n",
        "        \"\"\"\n",
        "        Projects the low-rank gradients back to the full-rank space.\n",
        "\n",
        "        Args:\n",
        "            low_rank_grad (torch.Tensor): The low-rank gradients.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The full-rank gradients.\n",
        "        \"\"\"\n",
        "        full_rank_grad = self.inverse_transform(self.ortho_matrix, self.transformed_low_rank)\n",
        "        return full_rank_grad * self.scale\n",
        "\n",
        "    # svd decomposition\n",
        "    def get_orthogonal_matrix(self, weights, rank_all):\n",
        "        \"\"\"\n",
        "        Computes the orthogonal matrix using SVD decomposition.\n",
        "\n",
        "        Args:\n",
        "            weights (torch.Tensor): The weights to decompose.\n",
        "            rank_all (int): The desired rank of the decomposition.\n",
        "\n",
        "        Returns:\n",
        "            tuple: A tuple containing the core and factors of the orthogonal matrix.\n",
        "        \"\"\"\n",
        "        module_params = weights\n",
        "        if module_params.data.dtype != torch.float:\n",
        "            matrix = module_params.data.float()\n",
        "        else:\n",
        "            matrix = module_params.data\n",
        "        tucker_tensor = tucker(matrix, rank=rank_all)\n",
        "        return tucker_tensor\n",
        "\n",
        "    def transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors, transpose=True)\n",
        "\n",
        "    def inverse_transform(self, tensor, x):\n",
        "        \"\"\"\n",
        "        Inverse transforms the input tensor using the factors of the orthogonal matrix.\n",
        "\n",
        "        Args:\n",
        "            tensor (tuple): A tuple containing the core and factors of the orthogonal matrix.\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The inverse transformed tensor.\n",
        "        \"\"\"\n",
        "        _, factors = tensor\n",
        "        return tenalg.multi_mode_dot(x, factors)\n",
        "\n",
        "\n",
        "\n",
        "class Fourier_GaLoreAdamW(Optimizer):\n",
        "    \"\"\"\n",
        "    Implements Adam algorithm with weight decay fix as introduced in [Decoupled Weight Decay\n",
        "    Regularization](https://arxiv.org/abs/1711.05101).\n",
        "\n",
        "    Parameters:\n",
        "        params (`Iterable[nn.parameter.Parameter]`):\n",
        "            Iterable of parameters to optimize or dictionaries defining parameter groups.\n",
        "        lr (`float`, *optional*, defaults to 0.001):\n",
        "            The learning rate to use.\n",
        "        betas (`Tuple[float,float]`, *optional*, defaults to `(0.9, 0.999)`):\n",
        "            Adam's betas parameters (b1, b2).\n",
        "        eps (`float`, *optional*, defaults to 1e-06):\n",
        "            Adam's epsilon for numerical stability.\n",
        "        weight_decay (`float`, *optional*, defaults to 0.0):\n",
        "            Decoupled weight decay to apply.\n",
        "        correct_bias (`bool`, *optional*, defaults to `True`):\n",
        "            Whether or not to correct bias in Adam (for instance, in Bert TF repository they use `False`).\n",
        "        no_deprecation_warning (`bool`, *optional*, defaults to `False`):\n",
        "            A flag used to disable the deprecation warning (set to `True` to disable the warning).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        params: Iterable[nn.parameter.Parameter],\n",
        "        lr: float = 1e-3,\n",
        "        betas: Tuple[float, float] = (0.9, 0.999),\n",
        "        eps: float = 1e-6,\n",
        "        weight_decay: float = 0.0,\n",
        "        correct_bias: bool = True,\n",
        "        no_deprecation_warning: bool = False,\n",
        "    ):\n",
        "        if not no_deprecation_warning:\n",
        "            warnings.warn(\n",
        "                \"This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch\"\n",
        "                \" implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this\"\n",
        "                \" warning\",\n",
        "                FutureWarning,\n",
        "            )\n",
        "        require_version(\"torch>=1.5.0\")  # add_ with alpha\n",
        "        if lr < 0.0:\n",
        "            raise ValueError(f\"Invalid learning rate: {lr} - should be >= 0.0\")\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[0]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(f\"Invalid beta parameter: {betas[1]} - should be in [0.0, 1.0)\")\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(f\"Invalid epsilon value: {eps} - should be >= 0.0\")\n",
        "        defaults = {\"lr\": lr, \"betas\": betas, \"eps\": eps, \"weight_decay\": weight_decay, \"correct_bias\": correct_bias}\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure: Callable = None):\n",
        "        \"\"\"\n",
        "        Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (`Callable`, *optional*): A closure that reevaluates the model and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            for p in group[\"params\"]:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\"Adam does not support sparse gradients, please consider SparseAdam instead\")\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                if \"step\" not in state:\n",
        "                    state[\"step\"] = 0\n",
        "\n",
        "                if 'dim' not in group:\n",
        "                    group['dim'] = 2\n",
        "\n",
        "                # GaLore Projection\n",
        "                if \"rank\" in group:\n",
        "                    if \"projector\" not in state:\n",
        "                        if group['dim'] <=2:\n",
        "                            state[\"projector\"] = GaLoreProjector(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                        else:\n",
        "                            state[\"projector\"] = GaLoreProjectorTensor(group[\"rank\"], update_proj_gap=group[\"update_proj_gap\"], scale=group[\"scale\"], proj_type=group[\"proj_type\"])\n",
        "                    grad = state[\"projector\"].project(grad, state[\"step\"])\n",
        "\n",
        "                # State initialization\n",
        "                if \"exp_avg\" not in state:\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state[\"exp_avg\"] = torch.zeros_like(grad)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state[\"exp_avg_sq\"] = torch.zeros_like(grad)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state[\"exp_avg\"], state[\"exp_avg_sq\"]\n",
        "                beta1, beta2 = group[\"betas\"]\n",
        "\n",
        "                state[\"step\"] += 1\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                # In-place operations to update the averages at the same time\n",
        "                exp_avg.mul_(beta1).add_(grad, alpha=(1.0 - beta1))\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1.0 - beta2)\n",
        "                denom = exp_avg_sq.sqrt().add_(group[\"eps\"])\n",
        "\n",
        "                step_size = group[\"lr\"]\n",
        "                if group[\"correct_bias\"]:  # No bias correction for Bert\n",
        "                    bias_correction1 = 1.0 - beta1 ** state[\"step\"]\n",
        "                    bias_correction2 = 1.0 - beta2 ** state[\"step\"]\n",
        "                    step_size = step_size * math.sqrt(bias_correction2) / bias_correction1\n",
        "\n",
        "                # compute norm gradient\n",
        "                norm_grad = exp_avg / denom\n",
        "\n",
        "                # GaLore Projection Back\n",
        "                if \"rank\" in group:\n",
        "                    norm_grad = state[\"projector\"].project_back(norm_grad)\n",
        "\n",
        "                p.add_(norm_grad, alpha=-step_size)\n",
        "\n",
        "                # Just adding the square of the weights to the loss function is *not*\n",
        "                # the correct way of using L2 regularization/weight decay with Adam,\n",
        "                # since that will interact with the m and v parameters in strange ways.\n",
        "                #\n",
        "                # Instead we want to decay the weights in a manner that doesn't interact\n",
        "                # with the m/v parameters. This is equivalent to adding the square\n",
        "                # of the weights to the loss with plain (non-momentum) SGD.\n",
        "                # Add weight decay at the end (fixed version)\n",
        "                if group[\"weight_decay\"] > 0.0:\n",
        "                    p.add_(p, alpha=(-group[\"lr\"] * group[\"weight_decay\"]))\n",
        "\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "Zahr3wd4ocu5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# bnb_config = BitsAndBytesConfig(\n",
        "#     load_in_4bit=True,\n",
        "#     bnb_4bit_quant_type=\"nf4\",  # Normalized Float 4 (better than standard FP4)\n",
        "#     bnb_4bit_use_double_quant=True,  # Uses secondary quantization for better precision\n",
        "#     bnb_4bit_compute_dtype=torch.float16  # Keeps computation in FP16 for stability\n",
        "# )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    # quantization_config=bnb_config,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "# from galore_torch import GaLoreAdamW, GaLoreAdamW8bit, GaLoreAdafactor\n",
        "\n",
        "# make parameters with \"rank\" to a single group, if param_name has \"mlp\" or \"attn\"\n",
        "galore_params = []\n",
        "target_modules_list = [\"attn\", \"mlp\"]\n",
        "for module_name, module in model.named_modules():\n",
        "    if not isinstance(module, nn.Linear):\n",
        "        continue\n",
        "\n",
        "    if not any(target_key in module_name for target_key in target_modules_list):\n",
        "        continue\n",
        "\n",
        "    # print('enable GaLore for weights in module: ', module_name)\n",
        "    galore_params.append(module.weight)\n",
        "id_galore_params = [id(p) for p in galore_params]\n",
        "# make parameters without \"rank\" to another group\n",
        "regular_params = [p for p in model.parameters() if id(p) not in id_galore_params]\n",
        "# then call galore_adamw\n",
        "param_groups = [{'params': regular_params},\n",
        "                {'params': galore_params, 'rank': 128, 'update_proj_gap': 50, 'scale': 1, 'proj_type': \"std\"}]\n",
        "\n",
        "\n",
        "optimizer = Fourier_GaLoreAdamW(param_groups, lr=1e-5, weight_decay=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvBwu6f_2JJz",
        "outputId": "bd2d8f37-2c29-4ba7-990c-c73a72f61fa9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-39e1370c7377>:285: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "he8J3r2s2qJ_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}